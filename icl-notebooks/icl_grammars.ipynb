{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aae1002-7b40-47b6-ad64-8b8a8166374f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dbdd0c42a444f3cbfa84dd0d9355bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ablating mlp  en\n",
      "before top k torch.Size([32, 4096])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2078 is out of bounds for dimension 1 with size 331",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 92\u001b[0m\n\u001b[1;32m     89\u001b[0m                 model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;28mint\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;124m'\u001b[39m])]\u001b[38;5;241m.\u001b[39mmlp\u001b[38;5;241m.\u001b[39mdown_proj\u001b[38;5;241m.\u001b[39mweight[\u001b[38;5;28mint\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneuron\u001b[39m\u001b[38;5;124m'\u001b[39m])] \u001b[38;5;241m=\u001b[39m component_cache[row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneuron\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 92\u001b[0m         ablate_model(col, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmlp\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     93\u001b[0m         ablate_model(col, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattn\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_answer\u001b[39m(text):\n",
      "Cell \u001b[0;32mIn[1], line 89\u001b[0m, in \u001b[0;36mablate_model\u001b[0;34m(col, component)\u001b[0m\n\u001b[1;32m     87\u001b[0m component_cache \u001b[38;5;241m=\u001b[39m component_cache\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m---> 89\u001b[0m     model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;28mint\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;124m'\u001b[39m])]\u001b[38;5;241m.\u001b[39mmlp\u001b[38;5;241m.\u001b[39mdown_proj\u001b[38;5;241m.\u001b[39mweight[\u001b[38;5;28mint\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneuron\u001b[39m\u001b[38;5;124m'\u001b[39m])] \u001b[38;5;241m=\u001b[39m component_cache[row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneuron\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2078 is out of bounds for dimension 1 with size 331"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForCausalLM, AutoConfig,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "import bitsandbytes\n",
    "from accelerate import infer_auto_device_map\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from datasets import Dataset, load_dataset\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "import yaml\n",
    "import argparse\n",
    "import numpy as np\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "\n",
    "# parser.add_argument('--config', type=str, help='path to the model training config file, found in broca/configs')\n",
    "# parser.add_argument('--stype', type=int, help='grammar structure col number, found in broca/data-gen')\n",
    "\n",
    "# args = parser.parse_args()\n",
    "# with open(args.config, 'r') as f:\n",
    "#     config = yaml.safe_load(f)\n",
    "\n",
    "args = { \"config\": \"/mnt/align4_drive/arunas/broca/configs/mistral-icl-config\", \"stype\": 7 }\n",
    "with open(args[\"config\"], 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "PREFIX = config[\"prefix\"]\n",
    "MODEL_NAME = config[\"model_name\"]\n",
    "MODEL_PATH = config[\"model_path\"]\n",
    "ABLATION = config[\"ablation\"]\n",
    "DATA_PATH = config[\"data_path\"]\n",
    "NUM_DEMONSTRATIONS = config[\"num_dems\"]\n",
    "BATCH_SIZE = config[\"batch_size\"]\n",
    "FINAL_CSV_SUBPATH = config[\"final_csv_subpath\"]\n",
    "\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=False,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model_config = AutoConfig.from_pretrained(MODEL_PATH)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, config=model_config, device_map=\"auto\", padding_side=\"left\")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_PATH, config=model_config, device_map='auto') # Load the model\n",
    "\n",
    "device_map = infer_auto_device_map(model)\n",
    "\n",
    "df = pd.read_csv(f'{DATA_PATH}')\n",
    "gCols = [col for col in list(df.columns) if not 'ng' in col]\n",
    "# col = gCols[args.stype]\n",
    "col = gCols[args[\"stype\"]]\n",
    "\n",
    "if (ABLATION):\n",
    "    MEAN_ABLATION = config[\"mean_ablation\"]\n",
    "    MEAN_PICKLES_PATH = config[\"mean_pickles_path\"]\n",
    "    MEAN_PICKLES_SUBPATH = config[\"mean_pickles_subpath\"]\n",
    "    PATCH_PICKLES_PATH = config[\"patch_pickles_path\"]\n",
    "    PATCH_PICKLES_SUBPATH = config[\"patch_pickles_subpath\"]\n",
    "    def retrieve_topK(col, component, topK):\n",
    "        with open(f'{PATCH_PICKLES_PATH}/{component}/{PATCH_PICKLES_SUBPATH}/{col}.pkl', 'rb') as f:\n",
    "            print(f'ablating {component} ', col)\n",
    "            component_cache = pickle.load(f)\n",
    "            print('before top k', component_cache.shape)\n",
    "            component_cache = component_cache.cpu()\n",
    "            flattened_effects_cache = component_cache.view(-1)\n",
    "            top_neurons = flattened_effects_cache.topk(k=int(topK * flattened_effects_cache.shape[-1]))\n",
    "            two_d_indices = torch.cat((((top_neurons[1] // component_cache.shape[1]).unsqueeze(1)), ((top_neurons[1] % component_cache.shape[1]).unsqueeze(1))), dim=1)            \n",
    "            df = pd.DataFrame(two_d_indices, columns=['layer', 'neuron'])\n",
    "        return df\n",
    "\n",
    "    def ablate_model(col, component):\n",
    "        df = retrieve_topK(col, component, 0.01)\n",
    "        with open(f'{MEAN_PICKLES_PATH}/{component}/{MEAN_PICKLES_SUBPATH}/{col}.pkl', 'rb') as mf:\n",
    "            component_cache = pickle.load(mf)\n",
    "            component_cache = component_cache.cpu()\n",
    "            print('means ', component_cache.shape)\n",
    "            for idx, row in df.iterrows():\n",
    "                model.model.layers[int(row['layer'])].mlp.down_proj.weight[int(row['neuron'])] = component_cache[row['layer'], row['neuron']]\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        ablate_model(col, 'mlp')\n",
    "        ablate_model(col, 'attn')\n",
    "\n",
    "def parse_answer(text):\n",
    "    answers = []\n",
    "    for t in text:\n",
    "        ans = t.split(\"A:\")[-1].strip()\n",
    "        answers.append(ans)\n",
    "    return answers\n",
    "\n",
    "def construct_prompt(train_dataset, num_demonstrations):\n",
    "    assert num_demonstrations > 0\n",
    "    prompt = ''\n",
    "    train_examples = train_dataset.shuffle(seed=42).select(range(num_demonstrations))\n",
    "    for exemplar_num in range(num_demonstrations):\n",
    "        train_example = train_examples[exemplar_num]\n",
    "        use_bad_sentence = random.choice([True, False])\n",
    "        exemplar = \"Q: Is this sentence grammatical? Yes or No: \"\n",
    "        if use_bad_sentence:\n",
    "            exemplar += train_example[\"ng-\" + col]\n",
    "            exemplar += \"\\nA: No\"\n",
    "        else:\n",
    "            exemplar += train_example[col]\n",
    "            exemplar += \"\\nA: Yes\"\n",
    "        exemplar += \"\\n\\n\"\n",
    "        prompt += exemplar\n",
    "    return prompt\n",
    "\n",
    "def compute_accuracy(preds, golds):\n",
    "    assert len(preds) == len(golds)\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for pred, gold in zip(preds, golds):\n",
    "        if pred == gold:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_aligned_words_measures(texts: str, \n",
    "                               answers: str,\n",
    "                               measure: str,\n",
    "                               model: GPT2LMHeadModel, \n",
    "                               tokenizer: GPT2Tokenizer) -> list[str]:\n",
    "    if measure not in {'prob', 'surp'}:\n",
    "        sys.stderr.write(f\"{measure} not recognized\\n\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    datas = []\n",
    "    for t in range(len(texts)):\n",
    "        text = f'{texts[t]} {answers[t]}'\n",
    "        data = []\n",
    "    \n",
    "        ids = tokenizer(text, return_tensors='pt').to('cuda')\n",
    "        input_ids = ids.input_ids.flatten().data\n",
    "        target_ids = ids.input_ids[:,1:]\n",
    "    \n",
    "        # get output\n",
    "        logits = model(**ids).logits\n",
    "        output = torch.nn.functional.log_softmax(logits, dim=-1)\n",
    "        if measure == 'surp':\n",
    "            output = -(output/torch.log(torch.tensor(2.0)))\n",
    "        else:\n",
    "            output = torch.exp(output)\n",
    "    \n",
    "        # get by token measures \n",
    "        target_measures = output[:,:-1, :]\n",
    "        # use gather to get the output for each target item in the batch\n",
    "        target_measures = target_measures.gather(-1,\n",
    "                                 target_ids.unsqueeze(2)).flatten().tolist()\n",
    "        \n",
    "        tokens = tokenizer.convert_ids_to_tokens(input_ids)[1:]\n",
    "        words = text.split(' ')\n",
    "    \n",
    "        # A lil loop to force align words \n",
    "        current_word = words.pop(0)\n",
    "        current_token = tokens.pop(0).replace('▁', '')\n",
    "        measure = 0\n",
    "        while len(data) != len(text.split(' ')) and len(target_measures) > 0:\n",
    "            if current_word == current_token:\n",
    "                data.append((current_word, measure))\n",
    "                measure = 0\n",
    "                if words:\n",
    "                    current_word = words.pop(0)\n",
    "                    current_token = tokens.pop(0).replace('▁', '')\n",
    "                    measure += target_measures.pop(0)\n",
    "            else:\n",
    "                measure += target_measures.pop(0)\n",
    "                current_token += tokens.pop(0).replace('▁', '')\n",
    "                data.append((current_token, measure))\n",
    "        datas.append(data)\n",
    "    return datas\n",
    "\n",
    "preds = []\n",
    "golds = []\n",
    "\n",
    "f = pd.DataFrame(columns=[\"type\", \"prompt\", \"q\", \"prediction\", \"gold\", \"surprisal\", \"int-grad\"])\n",
    "f['type'] = 'test'\n",
    "g = pd.DataFrame(columns=['accuracy', 'type'])\n",
    "datasets = {}\n",
    "np.random.seed(42)\n",
    "datasets[col] = Dataset.from_pandas(pd.DataFrame(df[[col, 'ng-' + col]].copy())).train_test_split(test_size=0.5)\n",
    "\n",
    "def get_master_prompt(lang):\n",
    "    en_verbs = [\"affirms\", \"bring\", \"brings\", \"carries\", \"carry\", \"climb\", \"climbs\", \"eat\", \"eats\", \"hold\", \"holds\", \"knows\", \"notices\", \"read\", \"reads\", \"says\", \"sees\", \"take\", \"takes\"]\n",
    "    en_verbs_past = [\"affirmed\", \"brought\", \"carried\", \"climbed\", \"ate\", \"held\", \"knew\", \"noticed\", \"read\", \"said\", \"saw\", \"took\"]\n",
    "    en_verbs_infinitive = [\"to affirm\", \"to bring\", \"to carry\", \"to climb\", \"to eat\", \"to hold\", \"to know\", \"to notice\", \"to read\", \"to say\", \"to see\", \"to take\"]\n",
    "    en_verbs_passive = [\"affirmed\", \"brought\", \"carried\", \"climbed\", \"eaten\", \"held\", \"known\", \"noticed\", \"read\", \"said\", \"seen\", \"taken\"]\n",
    "    en_nouns = ['author', 'banana', 'biscuit', 'book', 'bottle', 'box', 'boy', 'bulb', 'cap', 'cat', 'chalk', 'chapter', 'cucumber', 'cup', 'dog', 'fish', 'fruit', 'girl', 'hill', 'man', 'meal', 'mountain', 'mouse', 'newspaper', 'pear', 'pizza', 'poem', 'poet', 'rock', 'roof', 'speaker', 'staircase', 'story', 'teacher', 'toy', 'tree', 'woman', 'writer']\n",
    "    en_nouns_plural = ['authors', 'boys', 'cats', 'dogs', 'girls', 'men', 'poets', 'speakers', 'teachers', 'women', 'writers']\n",
    "    proper_nouns = ['Gomu', 'Harry', 'John', 'Leela', 'Maria', 'Sheela', 'Tom']\n",
    "    \n",
    "    ita_verbs = ['legge', 'leggono', 'mangia', 'mangiano', 'porta', 'portano', 'prende', 'prendono',\n",
    "                'salgono', 'scala', 'tengono', 'tiene', 'vede', 'dice', 'osserva', 'sa', 'afferma']\n",
    "    ita_verbs_past = ['è letto', 'è mangiato', 'è portato', 'è preso', 'è scalata', 'è scalato', 'è tenuto', 'è salito']\n",
    "    ita_verbs_infinitive = ['leggere', 'magiare', 'portare', 'prendere', 'scalare', 'tenere', 'salire']\n",
    "    ita_nouns = ['albero', 'autore', 'banana', 'biscotto', 'bottiglia', 'cane', 'capitolo', 'cappello', 'cetriolo', 'collina', 'donna', 'frutta', 'gatto', 'gesso', 'giocattolo', 'giornale', 'insegnante', 'lampadina', 'libro', 'montagna', 'oratorio', 'pasto', 'pera', 'pesce', 'pizza', 'poema', 'poeta', 'ragazza', 'ragazzo', 'roccia', 'scala', 'scatola', 'scrittore', 'storia', 'tazza', 'tetto', 'topo', 'uomo']\n",
    "    ita_nouns_plurals = ['alberi', 'autori', 'banane', 'biscotti', 'bottiglie', 'cani', 'capitoli', 'cappelli', 'cetrioli', 'colline', 'donne', 'frutta', 'gatti', 'gessi', 'giocattoli', 'giornali', 'insegnanti', 'lampadine', 'libri', 'montagne', 'oratori', 'pasti', 'pere', 'pesci', 'pizze', 'poemi', 'poeti', 'ragazze', 'ragazzi', 'rocce', 'scale', 'scatole', 'scrittori', 'storie', 'tazze', 'tetti', 'topi', 'uomini']\n",
    "    ita_nouns_la = [\"pera\", \"banana\", \"bottiglia\", \"scatola\", \"lampadina\", \"credenza\", \"tazza\", \"frutta\", \"ragazza\", \"collina\", \"montagna\", \"pizza\", \"roccia\", \"scala\", \"storia\", \"donna\"]\n",
    "    ita_nouns_lo = [\"scrittore\"]\n",
    "    ita_nouns_il = [\"biscotto\", \"libro\", \"ragazzo\", \"cappello\", \"gatto\", \"capitolo\", \"gesso\", \"cetriolo\", \"cane\", \"oratorio\", \"pesce\", \"pasto\", \"topo\", \"giornale\", \"poeta\", \"poema\", \"tetto\", \"giocattolo\"]\n",
    "    ita_nouns_gli = [\"scrittori\", \"uomini\", \"oratori\", \"insegnanti\", \"autori\"]\n",
    "    ita_nouns_i = [\"ragazzi\", \"gatti\", \"cani\", \"poeti\"]\n",
    "    ita_nouns_il_vowel = [\"uomo\", \"oratore\", \"insegnante\", \"albero\", \"autore\"]\n",
    "    ita_nouns_le = [\"donne\"]\n",
    "    \n",
    "    it_nouns_kon = ['author', 'biscuit', 'book', 'boy', 'cap', 'cat', 'chalk', 'chapter', 'cucumber', 'dog', 'fish', 'man', 'meal', 'mouse', 'newspaper', 'poet', 'rock', 'roof', 'speaker', 'teacher', 'toy', 'writer']\n",
    "    it_nouns_kar = ['banana', 'bottle', 'box', 'bulb', 'cabinet', 'cup', 'fruit', 'girl', 'hill', 'mountain', 'pear', 'pizza', 'poem', 'staircase', 'story', 'tree', 'woman']\n",
    "    it_nouns_kons = ['authors', 'boys', 'cats', 'dogs', 'men', 'poets', 'speakers', 'teachers', 'writers']\n",
    "    it_nouns_kars = [\"girls\", \"women\"]\n",
    "    jp_nouns = [\"梨\", \"著者\", \"バナナ\", \"ビスケット\", \"本\", \"ボトル\", \"箱\", \"男の子\", \"電球\", \"帽子\", \"猫\", \"章\", \"白亜\", \"コップ\", \"胡瓜\", \"犬\", \"魚\", \"果物\", \"女の子\", \"丘\", \"男\", \"食事\", \"山\", \"マウス\", \"新聞\", \"麺\", \"詩人\", \"詩\", \"岩石\", \"屋根\", \"スピーカー\", \"階段\", \"小説\", \"先生\", \"玩具\", \"木\", \"女\", \"著者\", \"ピザ\", \"梨\", \"著者\", \"バナナ\", \"ビスケット\", \"本\", \"ボトル\", \"箱\", \"男の子\", \"電球\", \"帽子\", \"猫\", \"章\", \"白亜\", \"コップ\", \"胡瓜\", \"犬\", \"魚\", \"果物\", \"女の子\", \"丘\", \"男性\", \"食事\", \"山\", \"マウス\", \"新聞\", \"麺\", \"詩人\", \"詩\", \"岩石\", \"屋根\", \"スピーカー\", \"階段\", \"小説\", \"先生\", \"玩具\", \"木\", \"女性\", \"著者\", \"ピザ\"]\n",
    "    jp_verbs = [\"食べる\",\"読む\",\"運ぶ\",\"のぼる\",\"とる\",\"持つ\",\"もたらす\", \"食べる\",\"読む\",\"運ぶ\",\"のぼる\",\"とる\",\"持つ\",\"もたらす\"]\n",
    "    jp_verbs_passive = [\"食べられる\", \"読まれる\", \"運ばれる\", \"のぼられる\", \"とられる\", \"持たれる\", \"持たれる\"]\n",
    "    jp_suffixes = [ \"は\", \"が\", \"を\", \"と\", \"に\", \"ない\", \"た\" ]\n",
    "    jp_proper_nouns = [\"シーラ\", \"ゴム\", \"ハリー\", \"ジョン\", \"リーラ\", \"マリア\", \"トム\"]\n",
    "\n",
    "    if 'en' == \"\".join(lang[:2]):\n",
    "        intro = \"We will give you examples of English sentences that follow or violate the rules of a shared grammar, along with labels 'Yes' or 'No'. You will then generate a label, 'Yes' or 'No', for a new unlabeled sentence that may follow or violate the same grammar rules.\"\n",
    "        # verbs = f\"\"\"The sentences may use verbs ({', '.join(en_verbs)});\"\"\"\n",
    "        # pastTenseVerbs = f\"\"\"or their corresponding past tense forms ({', '.join(en_verbs_past)});\"\"\" \n",
    "        # infinitiveVerbs = f\"\"\"infinitive forms ({', '.join(en_verbs_infinitive)});\"\"\"\n",
    "        # passiveVerbs = f\"\"\"or passive forms ({', '.join(en_verbs_passive)}).\"\"\"\n",
    "        # nouns = f\"\"\"The sentences may use nouns ({', '.join(set(en_nouns + en_nouns_plural))}) for the subjects and objects.\"\"\"\n",
    "        # properNouns = f\"\"\"The sentences may use proper nouns ({', '.join(set(proper_nouns))}).\"\"\"\n",
    "        # return f\"\"\"1.{intro}\\n2.{verbs} {pastTenseVerbs} {infinitiveVerbs} {passiveVerbs}\\n3.{nouns}\\n4.{properNouns}\"\"\"\n",
    "        return f\"{intro}\"\n",
    "\n",
    "    elif 'it' == \"\".join(lang[:2]) and (len(lang) <=2 or lang[2] != 'a'):\n",
    "        intro = \"We will give you examples of English sentences stylized to Italian syntax that follow or violate the rules of a shared grammar, along with labels 'Yes' or 'No'. You will then generate a label, 'Yes' or 'No', for a new unlabeled sentence that may follow or violate the same grammar rules.\"\n",
    "        # verbs = f\"\"\"The sentences may use verbs ({', '.join(en_verbs)});\"\"\"\n",
    "        # pastTenseVerbs = f\"\"\"or their corresponding past tense forms ({', '.join(en_verbs_past)});\"\"\" \n",
    "        # infinitiveVerbs = f\"\"\"infinitive forms ({', '.join(en_verbs_infinitive)});\"\"\"\n",
    "        # passiveVerbs = f\"\"\"or passive forms ({', '.join(en_verbs_passive)}).\"\"\"\n",
    "        # nouns = f\"\"\"The sentences may use nouns ({', '.join(set(en_nouns + en_nouns_plural))}) for the subjects and objects.\"\"\"\n",
    "        # properNouns = f\"\"\"The sentences may use proper nouns ({', '.join(set(proper_nouns))}).\"\"\"\n",
    "        gendered = f\"\"\"The nouns in the sentences have specific gender determiners - 'kar' (used by {', '.join(set(it_nouns_kar))}); 'kon' (used by {', '.join(set(it_nouns_kon))}); 'kars' (used by {', '.join(set(it_nouns_kars))}); 'kons' (used by {', '.join(set(it_nouns_kons))}).\"\"\"\n",
    "        # return f\"\"\"1.{intro}\\n2.{verbs} {pastTenseVerbs} {infinitiveVerbs} {passiveVerbs}\\n3.{nouns}\\n4.{properNouns}\\n5.{gendered}\"\"\"\n",
    "        return f\"1. {intro}\\n2. {gendered}\"\n",
    "    \n",
    "    elif 'ita' == \"\".join(lang[:3]):\n",
    "        intro = \"We will give you examples of Italian sentences that follow or violate the rules of a shared grammar, along with labels 'Yes' or 'No'. You will then generate a label, 'Yes' or 'No', for a new unlabeled sentence that may follow or violate the same grammar rules.\"\n",
    "        # verbs = f\"\"\"The sentences may use verbs ({', '.join(ita_verbs)});\"\"\"\n",
    "        # pastTenseVerbs = f\"\"\"or their corresponding past tense forms ({', '.join(ita_verbs_past)});\"\"\" \n",
    "        # infinitiveVerbs = f\"\"\"infinitive forms ({', '.join(ita_verbs_infinitive)});\"\"\"\n",
    "        # passiveVerbs = f\"\"\"or passive forms ({', '.join(ita_verbs_past)}).\"\"\"\n",
    "        # nouns = f\"\"\"The sentences may use nouns ({', '.join(set(ita_nouns + ita_nouns_plurals))}) for the subjects and objects.\"\"\"\n",
    "        # properNouns = f\"\"\"The sentences may use proper nouns ({', '.join(set(proper_nouns))}).\"\"\"\n",
    "        # gendered = f\"\"\"The nouns in the sentences have specific gender determiners - 'la' (used by {', '.join(set(ita_nouns_la))}); 'lo' (used by {', '.join(set(ita_nouns_lo))}); 'le' (used by {', '.join(set(ita_nouns_le))}); 'il' (used by {', '.join(set(ita_nouns_il))}, \"l'\" (used by {', '.join(set(ita_nouns_il_vowel))}); 'i' (used by {', '.join(set(ita_nouns_i))}, and 'gli' (used by {', '.join(set(ita_nouns_gli))}.\"\"\"\n",
    "        # return f\"\"\"1.{intro}\\n2.{verbs} {pastTenseVerbs} {infinitiveVerbs} {passiveVerbs}\\n3.{nouns}\\n4.{properNouns}\\n5.{gendered}\"\"\"\n",
    "        return f\"{intro}\"\n",
    "    \n",
    "    elif 'jap' == \"\".join(lang[:3]):\n",
    "        intro = \"We will give you examples of Japanese sentences that follow or violate the rules of a shared grammar, along with labels 'Yes' or 'No'. You will then generate a label, 'Yes' or 'No', for a new unlabeled sentence that may follow or violate the same grammar rules.\"\n",
    "        # verbs = f\"\"\"The sentences may use verbs ({', '.join(jp_verbs)});\"\"\"\n",
    "        # passiveVerbs = f\"\"\"or passive forms ({', '.join(jp_verbs_passive)}).\"\"\"\n",
    "        # nouns = f\"\"\"The sentences may use nouns ({', '.join(set(jp_nouns))}) for the subjects and objects.\"\"\"\n",
    "        # suffixes = f\"\"\"The sentences may use suffixes ({', '.join(set(jp_suffixes))}) along with subjects, objects or verbs.\"\"\"\n",
    "        # properNouns = f\"\"\"The sentences may use proper nouns ({', '.join(set(jp_proper_nouns))}).\"\"\"\n",
    "        # return f\"\"\"1.{intro}\\n2.{verbs} {passiveVerbs}\\n3.{nouns}\\n4.{properNouns}\\n5.{suffixes}\"\"\"\n",
    "        return f\"{intro}\"\n",
    "    \n",
    "    elif 'jp' == \"\".join(lang[:2]):\n",
    "        intro = \"We will give you examples of English sentences stylized to Japanese syntax that follow or violate the rules of a shared grammar, along with labels 'Yes' or 'No'. You will then generate a label, 'Yes' or 'No', for a new unlabeled sentence that may follow or violate the same grammar rules.\"\n",
    "        # verbs = f\"\"\"The sentences may use verbs ({', '.join(en_verbs)});\"\"\"\n",
    "        # pastTenseVerbs = f\"\"\"or their corresponding past tense forms ({', '.join(en_verbs_past)});\"\"\" \n",
    "        # infinitiveVerbs = f\"\"\"infinitive forms ({', '.join(en_verbs_infinitive)});\"\"\"\n",
    "        # passiveVerbs = f\"\"\"or passive forms ({', '.join(en_verbs_passive)});\"\"\"\n",
    "        # nouns = f\"\"\"The sentences may use nouns ({', '.join(set(en_nouns + en_nouns_plural))}) for the subjects and objects.\"\"\"\n",
    "        # properNouns = f\"\"\"The sentences may use proper nouns ({', '.join(set(proper_nouns))}).\"\"\"\n",
    "        suffixes = f\"\"\"The sentences use Japanese topic markers and suffixes such as wa (commonly used after the subject); o, ni, ga, o-ta (commonly used after the object); reru(used after the verb).\"\"\"\n",
    "        # return f\"\"\"1.{intro}\\n2.{verbs} {pastTenseVerbs} {infinitiveVerbs} {passiveVerbs}\\n3.{nouns}\\n4.{properNouns}\\n5.{suffixes}\"\"\"\n",
    "        return f\"1. {intro}\\n2. {suffixes}\"\n",
    "\n",
    "if (not (os.path.exists(f\"{PREFIX}/broca/{MODEL_NAME}/experiments/{FINAL_CSV_SUBPATH}/{col}.csv\")) and not (os.path.exists(f\"{PREFIX}/broca/{MODEL_NAME}/experiments/{FINAL_CSV_SUBPATH}/{col}-acc.csv\"))):\n",
    "    master_prompt = get_master_prompt(col)\n",
    "    train_dataset = datasets[col]['train']\n",
    "    test_dataset = datasets[col]['test']\n",
    "    printAnswer = False\n",
    "    f = pd.DataFrame(columns=[\"type\", \"prompt\", \"q\", \"prediction\", \"gold\", \"surprisal\", \"int-grad\"])\n",
    "    for i in tqdm(range(0, len(test_dataset), BATCH_SIZE)):\n",
    "        test_sentences = []\n",
    "        fPrompts = []\n",
    "        fQs = []\n",
    "        fGolds = []\n",
    "        prompts = []\n",
    "        for batch_idx in range(BATCH_SIZE):\n",
    "            testBadOrGood = random.choice(['ng-', ''])\n",
    "            if (i + batch_idx) >= len(test_dataset):\n",
    "                break;\n",
    "            test_sentence = test_dataset[i + batch_idx]\n",
    "            prompt = construct_prompt(train_dataset, NUM_DEMONSTRATIONS)\n",
    "            \n",
    "            fPrompt = prompt\n",
    "            \n",
    "            # Append test example\n",
    "            prompt += \"Q: Is this sentence grammatical? Yes or No: \"\n",
    "            prompt += test_sentence[testBadOrGood + col]\n",
    "            prompt += \"\\nA:\"\n",
    "            \n",
    "            fQ = \"Q: Is this sentence grammatical? Yes or No: \" + test_sentence[testBadOrGood + col] + \"\\nA:\"\n",
    "            \n",
    "            if testBadOrGood == 'ng-':\n",
    "                golds.append(\"No\")\n",
    "                fGold = 'No'\n",
    "            else:\n",
    "                golds.append(\"Yes\")\n",
    "                fGold = 'Yes'\n",
    "            fGolds.append(fGold)\n",
    "            prompts.append(master_prompt + prompt)\n",
    "            test_sentences.append(test_sentence[testBadOrGood + col])\n",
    "            fPrompts.append(fPrompt)\n",
    "            fQs.append(fQ)\n",
    "            \n",
    "        # Get answer from model\n",
    "        model_inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True).to('cuda')\n",
    "        answers = model.generate(**model_inputs, pad_token_id=tokenizer.eos_token_id, max_new_tokens=2, top_p=0.9, temperature=0.1, do_sample=True)\n",
    "        answers = tokenizer.batch_decode(answers)[:BATCH_SIZE]\n",
    "\n",
    "        if printAnswer:\n",
    "            print(answers)\n",
    "            printAnswer = False\n",
    "        \n",
    "        preds = preds + parse_answer(answers)\n",
    "        fPredictions = parse_answer(answers)\n",
    "        fSurprisals = get_aligned_words_measures(test_sentences, parse_answer(answers), \"surp\", model, tokenizer)\n",
    "        for batch_idx in range(len(fPrompts)):\n",
    "            f = pd.concat([f, pd.DataFrame([{'type': col, 'prompt': prompts[batch_idx], 'q' :test_sentences[batch_idx], 'prediction': fPredictions[batch_idx], 'gold': fGolds[batch_idx], 'surprisal': fSurprisals[batch_idx], 'int-grad': 0}])]).reset_index(drop=True)\n",
    "    # Evaluate\n",
    "    accuracy = compute_accuracy(preds, golds)\n",
    "    print(f\"{col} -- Accuracy: {accuracy:.2f}\\n\")\n",
    "    g = pd.concat([g, pd.DataFrame([{ 'trainType' : col, 'testType': col, 'accuracy': f\"{accuracy:.2f}\"}])])\n",
    "    f.to_csv(f\"{PREFIX}/broca/{MODEL_NAME}/experiments/{FINAL_CSV_SUBPATH}/{col}.csv\")\n",
    "    g.to_csv(f'{PREFIX}/broca/{MODEL_NAME}/experiments/{FINAL_CSV_SUBPATH}/{col}-acc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c21d98-b0b3-4df7-8a84-2ee93fdbd1fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
