Emergent hierarchical linguistic structure in large language models (LLMs) is believed to be fundamental in explaining their abilities on several language understanding tasks. All natural languages are structured hierarchically, and in humans, there are neurological mechanisms that enforce this structural restriction. The brain areas responsible for language processing in humans are more sensitive to sentences with hierarchical grammatical rules and systematically less sensitive to linearly structured languages (impossible under universal grammar restrictions) that are superficially similar. In this study, we investigate whether language models learn similar distinctions---i.e., whether they learn distinct mechanisms for processing different structures given superficially similar inputs. We generate a dataset of both hierarchical and linearly structured English grammars, as well as hierarchical and linear Italian and Japanese grammars that have been employed in human studies. We investigate the learning capacity of two pretrained LLMs--Mistral-7B and Llama-70B in an in-context learning setup and find that models are more accurate at learning hierarchical grammars versus linear grammars. We investigate whether there are separate mechanisms for processing sentences that comply versus those that do not comply with hierarchical structure. We then study differences in the local processing of these constructions among the MLP and attention modules in LMs. We find that there is significant overlap in the causally implicated neurons and heads across languages when processing real structures, but that there is almost no overlap in the same implicated heads for unreal structures. We also find small degrees of overlap between causally implicated neurons and heads across languages when processing unreal structures. Our results suggest that LLMs learn specialized regions for processing different types of structures and that these distinct mechanisms may be responsible for their linguistic abilities. % We additionally find that, when ablating the most causally important neurons/heads for real structures, it has little effect on accuracies in detecting linear structure grammaticality, and vice versa. This suggests that LMs learn specialized regions for processing different types of structures, and that these distinct mechanisms are responsible  
