{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51c3fff4-0db2-4de7-a053-f248357c053b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/align4_drive/arunas/miniconda3/envs/broca/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Matplotlib created a temporary cache directory at /tmp/matplotlib-n2elcqgc because the default path (/afs/csail.mit.edu/u/a/arunas/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "from nnsight import LanguageModel\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForCausalLM, AutoConfig,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "import bitsandbytes\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6759f3bc-ceba-49f5-b1c0-432253776baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ita', 'ita-r-1-null_subject', 'ita-r-2-subordinate', 'ita-r-3-passive',\n",
      "       'ita-u-1-negation', 'ita-u-2-invert', 'ita-u-3-gender', 'en',\n",
      "       'en-r-1-subordinate', 'en-r-2-passive', 'en-u-1-negation',\n",
      "       'en-u-2-inversion', 'en-u-3-qsubordinate', 'it', 'it-r-1-null_subject',\n",
      "       'it-r-2-passive', 'it-r-3-subordinate', 'it-u-1-negation',\n",
      "       'it-u-2-invert', 'it-u-3-gender', 'jp-r-1-sov', 'jp-r-2-passive',\n",
      "       'jp-r-3-subordinate', 'jp-u-1-negation', 'jp-u-2-invert',\n",
      "       'jp-u-3-past-tense', 'jap-r-1-sov', 'jap-r-2-passive',\n",
      "       'jap-u-1-negation', 'jap-u-2-invert', 'ng-ita',\n",
      "       'ng-ita-r-1-null_subject', 'ng-ita-r-2-subordinate',\n",
      "       'ng-ita-r-3-passive', 'ng-ita-u-1-negation', 'ng-ita-u-2-invert',\n",
      "       'ng-ita-u-3-gender', 'ng-en', 'ng-en-r-1-subordinate',\n",
      "       'ng-en-r-2-passive', 'ng-en-u-1-negation', 'ng-en-u-2-inversion',\n",
      "       'ng-en-u-3-qsubordinate', 'ng-it', 'ng-it-r-1-null_subject',\n",
      "       'ng-it-r-2-passive', 'ng-it-r-3-subordinate', 'ng-it-u-1-negation',\n",
      "       'ng-it-u-2-invert', 'ng-it-u-3-gender', 'ng-jp-r-1-sov',\n",
      "       'ng-jp-r-2-passive', 'ng-jp-r-3-subordinate', 'ng-jp-u-1-negation',\n",
      "       'ng-jp-u-2-invert', 'ng-jp-u-3-past-tense', 'ng-jap-r-1-sov',\n",
      "       'ng-jap-r-2-passive', 'ng-jap-u-1-negation', 'ng-jap-u-2-invert'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "os.environ['HF_TOKEN'] = \"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\"\n",
    "PREFIX = '/mnt/align4_drive/arunas'\n",
    "og = pd.read_csv(f'{PREFIX}/broca/data-gen/ngs.csv')\n",
    "\n",
    "# og = og[ list(set(og.columns) - set(['it', 'it-r-1-null_subject',\n",
    "#        'it-r-2-passive', 'it-r-3-subordinate', 'it-u-1-negation',\n",
    "#        'it-u-2-invert', 'it-u-3-gender', 'ng-it',\n",
    "#        'ng-it-r-1-null_subject', 'ng-it-r-2-passive', 'ng-it-r-3-subordinate',\n",
    "#        'ng-it-u-1-negation', 'ng-it-u-2-invert', 'ng-it-u-3-gender'])) ]\n",
    "\n",
    "print(og.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbce711b-36d9-4ab5-8676-87c54d4fd690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ita</th>\n",
       "      <th>ita-r-1-null_subject</th>\n",
       "      <th>ita-r-2-subordinate</th>\n",
       "      <th>ita-r-3-passive</th>\n",
       "      <th>ita-u-1-negation</th>\n",
       "      <th>ita-u-2-invert</th>\n",
       "      <th>ita-u-3-gender</th>\n",
       "      <th>en</th>\n",
       "      <th>en-r-1-subordinate</th>\n",
       "      <th>en-r-2-passive</th>\n",
       "      <th>...</th>\n",
       "      <th>ng-jp-r-1-sov</th>\n",
       "      <th>ng-jp-r-2-passive</th>\n",
       "      <th>ng-jp-r-3-subordinate</th>\n",
       "      <th>ng-jp-u-1-negation</th>\n",
       "      <th>ng-jp-u-2-invert</th>\n",
       "      <th>ng-jp-u-3-past-tense</th>\n",
       "      <th>ng-jap-r-1-sov</th>\n",
       "      <th>ng-jap-r-2-passive</th>\n",
       "      <th>ng-jap-u-1-negation</th>\n",
       "      <th>ng-jap-u-2-invert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>il cane porta il pesce</td>\n",
       "      <td>porta il pesce</td>\n",
       "      <td>Leela dice che il cane porta il pesce</td>\n",
       "      <td>il pesce è portato dal cane</td>\n",
       "      <td>il cane porta il no pesce</td>\n",
       "      <td>pesce il porta cane il</td>\n",
       "      <td>il cane porta il pesce</td>\n",
       "      <td>the dog carries the fish</td>\n",
       "      <td>Tom notices that the dog carries the fish</td>\n",
       "      <td>the fish is carried by the dog</td>\n",
       "      <td>...</td>\n",
       "      <td>the dog wa the fish carries o</td>\n",
       "      <td>the fish wa the dog ni to reru carry</td>\n",
       "      <td>Tom wa the dog ga the fish o carries notices to</td>\n",
       "      <td>the dog wa no the fish carries o</td>\n",
       "      <td>carries o fish the wa the dog</td>\n",
       "      <td>the dog wa the fish  o-ta  carry to</td>\n",
       "      <td>犬 は 魚 運ぶ を</td>\n",
       "      <td>魚 は 犬 運ばれる に</td>\n",
       "      <td>犬 は 魚 ない 運ぶ を</td>\n",
       "      <td>運ぶ を 魚 犬 は</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>il cane tiene il pesce</td>\n",
       "      <td>tiene il pesce</td>\n",
       "      <td>Sheela afferma che il cane tiene il pesce</td>\n",
       "      <td>il pesce è tenuto dal cane</td>\n",
       "      <td>il cane tiene il no pesce</td>\n",
       "      <td>pesce il tiene cane il</td>\n",
       "      <td>il cane tiene il pesce</td>\n",
       "      <td>the dog holds the fish</td>\n",
       "      <td>Tom claims that the dog holds the fish</td>\n",
       "      <td>the fish is held by the dog</td>\n",
       "      <td>...</td>\n",
       "      <td>the dog wa the fish holds o</td>\n",
       "      <td>the fish wa the dog ni to reru hold</td>\n",
       "      <td>Tom wa the dog ga the fish o holds claims to</td>\n",
       "      <td>the dog wa no the fish holds o</td>\n",
       "      <td>holds o fish the wa the dog</td>\n",
       "      <td>the dog wa the fish  o-ta  hold to</td>\n",
       "      <td>犬 は 魚 持つ を</td>\n",
       "      <td>魚 は 犬 持たれる に</td>\n",
       "      <td>犬 は 魚 ない 持つ を</td>\n",
       "      <td>持つ を 魚 犬 は</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>un cane prende il pesce</td>\n",
       "      <td>prende il pesce</td>\n",
       "      <td>Leela dice che un cane prende il pesce</td>\n",
       "      <td>il pesce è preso dal cane</td>\n",
       "      <td>un cane prende il no pesce</td>\n",
       "      <td>pesce il prende cane un</td>\n",
       "      <td>il cane prende il pesce</td>\n",
       "      <td>a dog takes the fish</td>\n",
       "      <td>Sheela sees that the dog takes the fish</td>\n",
       "      <td>the fish is taken by a dog</td>\n",
       "      <td>...</td>\n",
       "      <td>a dog wa the fish takes o</td>\n",
       "      <td>the fish wa a dog ni to reru take</td>\n",
       "      <td>Sheela wa the dog ga the fish o takes sees to</td>\n",
       "      <td>a dog wa no the fish takes o</td>\n",
       "      <td>takes o fish the wa a dog</td>\n",
       "      <td>a dog wa the fish  o-ta  take to</td>\n",
       "      <td>犬 は 魚 とる を</td>\n",
       "      <td>魚 は 犬 とられる に</td>\n",
       "      <td>犬 は 魚 ない とる を</td>\n",
       "      <td>とる を 魚 犬 は</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>il cane porta il pesce</td>\n",
       "      <td>porta il pesce</td>\n",
       "      <td>Gomu dice che il cane porta il pesce</td>\n",
       "      <td>il pesce è portato dal cane</td>\n",
       "      <td>il cane porta il no pesce</td>\n",
       "      <td>pesce il porta cane il</td>\n",
       "      <td>il cane porta il pesce</td>\n",
       "      <td>the dog brings the fish</td>\n",
       "      <td>Tom claims that the dog brings the fish</td>\n",
       "      <td>the fish is brought by the dog</td>\n",
       "      <td>...</td>\n",
       "      <td>the dog wa the fish brings o</td>\n",
       "      <td>the fish wa the dog ni to reru bring</td>\n",
       "      <td>Tom wa the dog ga the fish o brings claims to</td>\n",
       "      <td>the dog wa no the fish brings o</td>\n",
       "      <td>brings o fish the wa the dog</td>\n",
       "      <td>the dog wa the fish  o-ta  bring to</td>\n",
       "      <td>犬 は 魚 もたらす を</td>\n",
       "      <td>魚 は 犬 持たれる に</td>\n",
       "      <td>犬 は 魚 ない もたらす を</td>\n",
       "      <td>もたらす を 魚 犬 は</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>un cane porta un topo</td>\n",
       "      <td>porta un topo</td>\n",
       "      <td>Harry dice che un cane porta un topo</td>\n",
       "      <td>un topo è portato da un cane</td>\n",
       "      <td>un cane porta un no topo</td>\n",
       "      <td>topo un porta cane un</td>\n",
       "      <td>un cane porta un topo</td>\n",
       "      <td>a dog carries a mouse</td>\n",
       "      <td>Harry sees that the dog carries the mouse</td>\n",
       "      <td>a mouse is carried by a dog</td>\n",
       "      <td>...</td>\n",
       "      <td>a dog wa a mouse carries o</td>\n",
       "      <td>a mouse wa a dog ni to reru carry</td>\n",
       "      <td>Harry wa the dog ga the mouse o carries sees to</td>\n",
       "      <td>a dog wa no a mouse carries o</td>\n",
       "      <td>carries o mouse a wa a dog</td>\n",
       "      <td>a dog wa a mouse  o-ta  carry to</td>\n",
       "      <td>犬 は マウス 運ぶ を</td>\n",
       "      <td>マウス は 犬 運ばれる に</td>\n",
       "      <td>犬 は マウス ない 運ぶ を</td>\n",
       "      <td>運ぶ を マウス 犬 は</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>le ragazze leggono il capitolo</td>\n",
       "      <td>leggono il capitolo</td>\n",
       "      <td>Maria sa che le ragazze leggono il capitolo</td>\n",
       "      <td>il capitolo è letto dalle ragazze</td>\n",
       "      <td>le ragazze leggono il no capitolo</td>\n",
       "      <td>capitolo il leggono ragazze le</td>\n",
       "      <td>il ragazze leggono il capitolo</td>\n",
       "      <td>the girls read a chapter</td>\n",
       "      <td>Tom says that the girls read the chapter</td>\n",
       "      <td>a chapter is read by the girls</td>\n",
       "      <td>...</td>\n",
       "      <td>the girls wa a chapter read o</td>\n",
       "      <td>a chapter wa the girls ni to reru read</td>\n",
       "      <td>Tom wa the girls ga the chapter o read says to</td>\n",
       "      <td>the girls wa no a chapter read o</td>\n",
       "      <td>read o chapter a wa the girls</td>\n",
       "      <td>the girls wa a chapter  o-ta  read to</td>\n",
       "      <td>女の子 は 章 読む を</td>\n",
       "      <td>章 は 女の子 読まれる に</td>\n",
       "      <td>女の子 は 章 ない 読む を</td>\n",
       "      <td>読む を 章 女の子 は</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>i ragazzi leggono il libro</td>\n",
       "      <td>leggono il libro</td>\n",
       "      <td>Maria osserva che i ragazzi leggono il libro</td>\n",
       "      <td>il libro è letto dai ragazzi</td>\n",
       "      <td>i ragazzi leggono il no libro</td>\n",
       "      <td>libro il leggono ragazzi i</td>\n",
       "      <td>il ragazzi leggono il libro</td>\n",
       "      <td>the boys read the book</td>\n",
       "      <td>John notices that the boys read the book</td>\n",
       "      <td>the book is read by the boys</td>\n",
       "      <td>...</td>\n",
       "      <td>the boys wa the book read o</td>\n",
       "      <td>the book wa the boys ni to reru read</td>\n",
       "      <td>John wa the boys ga the book o read notices to</td>\n",
       "      <td>the boys wa no the book read o</td>\n",
       "      <td>read o book the wa the boys</td>\n",
       "      <td>the boys wa the book  o-ta  read to</td>\n",
       "      <td>男の子 は 本 読む を</td>\n",
       "      <td>本 は 男の子 読まれる に</td>\n",
       "      <td>男の子 は 本 ない 読む を</td>\n",
       "      <td>読む を 本 男の子 は</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>i ragazzi leggono il poema</td>\n",
       "      <td>leggono il poema</td>\n",
       "      <td>Gomu sa che i ragazzi leggono il poema</td>\n",
       "      <td>il poema è letto dai ragazzi</td>\n",
       "      <td>i ragazzi leggono il no poema</td>\n",
       "      <td>poema il leggono ragazzi i</td>\n",
       "      <td>il ragazzi leggono il poema</td>\n",
       "      <td>the boys read a poem</td>\n",
       "      <td>Leela sees that the boys read the poem</td>\n",
       "      <td>a poem is read by the boys</td>\n",
       "      <td>...</td>\n",
       "      <td>the boys wa a poem read o</td>\n",
       "      <td>a poem wa the boys ni to reru read</td>\n",
       "      <td>Leela wa the boys ga the poem o read sees to</td>\n",
       "      <td>the boys wa no a poem read o</td>\n",
       "      <td>read o poem a wa the boys</td>\n",
       "      <td>the boys wa a poem  o-ta  read to</td>\n",
       "      <td>男の子 は 詩 読む を</td>\n",
       "      <td>詩 は 男の子 読まれる に</td>\n",
       "      <td>男の子 は 詩 ない 読む を</td>\n",
       "      <td>読む を 詩 男の子 は</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>i ragazzi leggono la storia</td>\n",
       "      <td>leggono la storia</td>\n",
       "      <td>Harry sa che i ragazzi leggono la storia</td>\n",
       "      <td>la storia è letto dai ragazzi</td>\n",
       "      <td>i ragazzi leggono la no storia</td>\n",
       "      <td>storia la leggono ragazzi i</td>\n",
       "      <td>la ragazzi leggono la storia</td>\n",
       "      <td>the boys read a story</td>\n",
       "      <td>Maria states that the boys read the story</td>\n",
       "      <td>a story is read by the boys</td>\n",
       "      <td>...</td>\n",
       "      <td>the boys wa a story read o</td>\n",
       "      <td>a story wa the boys ni to reru read</td>\n",
       "      <td>Maria wa the boys ga the story o read states to</td>\n",
       "      <td>the boys wa no a story read o</td>\n",
       "      <td>read o story a wa the boys</td>\n",
       "      <td>the boys wa a story  o-ta  read to</td>\n",
       "      <td>男の子 は 小説 読む を</td>\n",
       "      <td>小説 は 男の子 読まれる に</td>\n",
       "      <td>男の子 は 小説 ない 読む を</td>\n",
       "      <td>読む を 小説 男の子 は</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>i ragazzi leggono il capitolo</td>\n",
       "      <td>leggono il capitolo</td>\n",
       "      <td>Leela vede che i ragazzi leggono il capitolo</td>\n",
       "      <td>il capitolo è letto dai ragazzi</td>\n",
       "      <td>i ragazzi leggono il no capitolo</td>\n",
       "      <td>capitolo il leggono ragazzi i</td>\n",
       "      <td>il ragazzi leggono il capitolo</td>\n",
       "      <td>the boys read the chapter</td>\n",
       "      <td>Tom says that the boys read the chapter</td>\n",
       "      <td>the chapter is read by the boys</td>\n",
       "      <td>...</td>\n",
       "      <td>the boys wa the chapter read o</td>\n",
       "      <td>the chapter wa the boys ni to reru read</td>\n",
       "      <td>Tom wa the boys ga the chapter o read says to</td>\n",
       "      <td>the boys wa no the chapter read o</td>\n",
       "      <td>read o chapter the wa the boys</td>\n",
       "      <td>the boys wa the chapter  o-ta  read to</td>\n",
       "      <td>男の子 は 章 読む を</td>\n",
       "      <td>章 は 男の子 読まれる に</td>\n",
       "      <td>男の子 は 章 ない 読む を</td>\n",
       "      <td>読む を 章 男の子 は</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>812 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                ita ita-r-1-null_subject  \\\n",
       "0            il cane porta il pesce       porta il pesce   \n",
       "1            il cane tiene il pesce       tiene il pesce   \n",
       "2           un cane prende il pesce      prende il pesce   \n",
       "3            il cane porta il pesce       porta il pesce   \n",
       "4             un cane porta un topo        porta un topo   \n",
       "..                              ...                  ...   \n",
       "807  le ragazze leggono il capitolo  leggono il capitolo   \n",
       "808      i ragazzi leggono il libro     leggono il libro   \n",
       "809      i ragazzi leggono il poema     leggono il poema   \n",
       "810     i ragazzi leggono la storia    leggono la storia   \n",
       "811   i ragazzi leggono il capitolo  leggono il capitolo   \n",
       "\n",
       "                              ita-r-2-subordinate  \\\n",
       "0           Leela dice che il cane porta il pesce   \n",
       "1       Sheela afferma che il cane tiene il pesce   \n",
       "2          Leela dice che un cane prende il pesce   \n",
       "3            Gomu dice che il cane porta il pesce   \n",
       "4            Harry dice che un cane porta un topo   \n",
       "..                                            ...   \n",
       "807   Maria sa che le ragazze leggono il capitolo   \n",
       "808  Maria osserva che i ragazzi leggono il libro   \n",
       "809        Gomu sa che i ragazzi leggono il poema   \n",
       "810      Harry sa che i ragazzi leggono la storia   \n",
       "811  Leela vede che i ragazzi leggono il capitolo   \n",
       "\n",
       "                       ita-r-3-passive                   ita-u-1-negation  \\\n",
       "0          il pesce è portato dal cane          il cane porta il no pesce   \n",
       "1           il pesce è tenuto dal cane          il cane tiene il no pesce   \n",
       "2            il pesce è preso dal cane         un cane prende il no pesce   \n",
       "3          il pesce è portato dal cane          il cane porta il no pesce   \n",
       "4         un topo è portato da un cane           un cane porta un no topo   \n",
       "..                                 ...                                ...   \n",
       "807  il capitolo è letto dalle ragazze  le ragazze leggono il no capitolo   \n",
       "808       il libro è letto dai ragazzi      i ragazzi leggono il no libro   \n",
       "809       il poema è letto dai ragazzi      i ragazzi leggono il no poema   \n",
       "810      la storia è letto dai ragazzi     i ragazzi leggono la no storia   \n",
       "811    il capitolo è letto dai ragazzi   i ragazzi leggono il no capitolo   \n",
       "\n",
       "                     ita-u-2-invert                  ita-u-3-gender  \\\n",
       "0            pesce il porta cane il          il cane porta il pesce   \n",
       "1            pesce il tiene cane il          il cane tiene il pesce   \n",
       "2           pesce il prende cane un         il cane prende il pesce   \n",
       "3            pesce il porta cane il          il cane porta il pesce   \n",
       "4             topo un porta cane un           un cane porta un topo   \n",
       "..                              ...                             ...   \n",
       "807  capitolo il leggono ragazze le  il ragazze leggono il capitolo   \n",
       "808      libro il leggono ragazzi i     il ragazzi leggono il libro   \n",
       "809      poema il leggono ragazzi i     il ragazzi leggono il poema   \n",
       "810     storia la leggono ragazzi i    la ragazzi leggono la storia   \n",
       "811   capitolo il leggono ragazzi i  il ragazzi leggono il capitolo   \n",
       "\n",
       "                            en                         en-r-1-subordinate  \\\n",
       "0     the dog carries the fish  Tom notices that the dog carries the fish   \n",
       "1       the dog holds the fish     Tom claims that the dog holds the fish   \n",
       "2         a dog takes the fish    Sheela sees that the dog takes the fish   \n",
       "3      the dog brings the fish    Tom claims that the dog brings the fish   \n",
       "4        a dog carries a mouse  Harry sees that the dog carries the mouse   \n",
       "..                         ...                                        ...   \n",
       "807   the girls read a chapter   Tom says that the girls read the chapter   \n",
       "808     the boys read the book   John notices that the boys read the book   \n",
       "809       the boys read a poem     Leela sees that the boys read the poem   \n",
       "810      the boys read a story  Maria states that the boys read the story   \n",
       "811  the boys read the chapter    Tom says that the boys read the chapter   \n",
       "\n",
       "                      en-r-2-passive  ...                   ng-jp-r-1-sov  \\\n",
       "0     the fish is carried by the dog  ...   the dog wa the fish carries o   \n",
       "1        the fish is held by the dog  ...     the dog wa the fish holds o   \n",
       "2         the fish is taken by a dog  ...       a dog wa the fish takes o   \n",
       "3     the fish is brought by the dog  ...    the dog wa the fish brings o   \n",
       "4        a mouse is carried by a dog  ...      a dog wa a mouse carries o   \n",
       "..                               ...  ...                             ...   \n",
       "807   a chapter is read by the girls  ...   the girls wa a chapter read o   \n",
       "808     the book is read by the boys  ...     the boys wa the book read o   \n",
       "809       a poem is read by the boys  ...       the boys wa a poem read o   \n",
       "810      a story is read by the boys  ...      the boys wa a story read o   \n",
       "811  the chapter is read by the boys  ...  the boys wa the chapter read o   \n",
       "\n",
       "                           ng-jp-r-2-passive  \\\n",
       "0       the fish wa the dog ni to reru carry   \n",
       "1        the fish wa the dog ni to reru hold   \n",
       "2          the fish wa a dog ni to reru take   \n",
       "3       the fish wa the dog ni to reru bring   \n",
       "4          a mouse wa a dog ni to reru carry   \n",
       "..                                       ...   \n",
       "807   a chapter wa the girls ni to reru read   \n",
       "808     the book wa the boys ni to reru read   \n",
       "809       a poem wa the boys ni to reru read   \n",
       "810      a story wa the boys ni to reru read   \n",
       "811  the chapter wa the boys ni to reru read   \n",
       "\n",
       "                               ng-jp-r-3-subordinate  \\\n",
       "0    Tom wa the dog ga the fish o carries notices to   \n",
       "1       Tom wa the dog ga the fish o holds claims to   \n",
       "2      Sheela wa the dog ga the fish o takes sees to   \n",
       "3      Tom wa the dog ga the fish o brings claims to   \n",
       "4    Harry wa the dog ga the mouse o carries sees to   \n",
       "..                                               ...   \n",
       "807   Tom wa the girls ga the chapter o read says to   \n",
       "808   John wa the boys ga the book o read notices to   \n",
       "809     Leela wa the boys ga the poem o read sees to   \n",
       "810  Maria wa the boys ga the story o read states to   \n",
       "811    Tom wa the boys ga the chapter o read says to   \n",
       "\n",
       "                    ng-jp-u-1-negation                ng-jp-u-2-invert  \\\n",
       "0     the dog wa no the fish carries o   carries o fish the wa the dog   \n",
       "1       the dog wa no the fish holds o     holds o fish the wa the dog   \n",
       "2         a dog wa no the fish takes o       takes o fish the wa a dog   \n",
       "3      the dog wa no the fish brings o    brings o fish the wa the dog   \n",
       "4        a dog wa no a mouse carries o      carries o mouse a wa a dog   \n",
       "..                                 ...                             ...   \n",
       "807   the girls wa no a chapter read o   read o chapter a wa the girls   \n",
       "808     the boys wa no the book read o     read o book the wa the boys   \n",
       "809       the boys wa no a poem read o       read o poem a wa the boys   \n",
       "810      the boys wa no a story read o      read o story a wa the boys   \n",
       "811  the boys wa no the chapter read o  read o chapter the wa the boys   \n",
       "\n",
       "                       ng-jp-u-3-past-tense ng-jap-r-1-sov ng-jap-r-2-passive  \\\n",
       "0       the dog wa the fish  o-ta  carry to     犬 は 魚 運ぶ を       魚 は 犬 運ばれる に   \n",
       "1        the dog wa the fish  o-ta  hold to     犬 は 魚 持つ を       魚 は 犬 持たれる に   \n",
       "2          a dog wa the fish  o-ta  take to     犬 は 魚 とる を       魚 は 犬 とられる に   \n",
       "3       the dog wa the fish  o-ta  bring to   犬 は 魚 もたらす を       魚 は 犬 持たれる に   \n",
       "4          a dog wa a mouse  o-ta  carry to   犬 は マウス 運ぶ を     マウス は 犬 運ばれる に   \n",
       "..                                      ...            ...                ...   \n",
       "807   the girls wa a chapter  o-ta  read to   女の子 は 章 読む を     章 は 女の子 読まれる に   \n",
       "808     the boys wa the book  o-ta  read to   男の子 は 本 読む を     本 は 男の子 読まれる に   \n",
       "809       the boys wa a poem  o-ta  read to   男の子 は 詩 読む を     詩 は 男の子 読まれる に   \n",
       "810      the boys wa a story  o-ta  read to  男の子 は 小説 読む を    小説 は 男の子 読まれる に   \n",
       "811  the boys wa the chapter  o-ta  read to   男の子 は 章 読む を     章 は 男の子 読まれる に   \n",
       "\n",
       "    ng-jap-u-1-negation ng-jap-u-2-invert  \n",
       "0         犬 は 魚 ない 運ぶ を        運ぶ を 魚 犬 は  \n",
       "1         犬 は 魚 ない 持つ を        持つ を 魚 犬 は  \n",
       "2         犬 は 魚 ない とる を        とる を 魚 犬 は  \n",
       "3       犬 は 魚 ない もたらす を      もたらす を 魚 犬 は  \n",
       "4       犬 は マウス ない 運ぶ を      運ぶ を マウス 犬 は  \n",
       "..                  ...               ...  \n",
       "807     女の子 は 章 ない 読む を      読む を 章 女の子 は  \n",
       "808     男の子 は 本 ない 読む を      読む を 本 男の子 は  \n",
       "809     男の子 は 詩 ない 読む を      読む を 詩 男の子 は  \n",
       "810    男の子 は 小説 ない 読む を     読む を 小説 男の子 は  \n",
       "811     男の子 は 章 ない 読む を      読む を 章 男の子 は  \n",
       "\n",
       "[812 rows x 60 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77ed83d8-1319-4b8b-8719-75f9d645392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nf4_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"meta-llama/Llama-2-70b-hf\", cache_dir='/mnt/align4_drive/arunas/llama-tensors/')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "           \"meta-llama/Llama-2-70b-hf\", config=config, device_map=\"auto\", padding_side=\"left\", cache_dir='/mnt/align4_drive/arunas/llama-tensors/'\n",
    "           )\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = LanguageModel(\"meta-llama/Llama-2-70b-hf\",  quantization_config=nf4_config, tokenizer=tokenizer, device_map='auto', cache_dir='/mnt/align4_drive/arunas/llama-tensors/') # Load the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8d89221-9e96-42ce-9607-0da6171c4538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt_from_df(filename):\n",
    "    data = list(pd.read_csv(filename)['prompt'])\n",
    "    data = [sentence.strip() for sentence in data]\n",
    "    data = [sentence for sentence in data if not sentence == '']\n",
    "    data = [sentence.replace('</s>', '\\n') for sentence in data]\n",
    "    golds = [sentence.strip().split(\"\\n\")[-1].strip().split('A:')[-1].strip() for sentence in data]\n",
    "    data = [sentence[: -len(golds[idx])].strip() for idx, sentence in enumerate(data)]\n",
    "    return data, golds\n",
    "\n",
    "types = [item for item in list(og.columns) if not 'ng-' in item]\n",
    "sType=types[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1a29000-5318-4e7f-82ed-c91d963404e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts, golds = get_prompt_from_df(f'{PREFIX}/broca/llama/experiments/llama-classification-train-test-det-{sType}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e5b7c34-62f7-42d7-b0b2-1cb45c45e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_effects_cache = torch.zeros((model.config.num_hidden_layers, model.config.hidden_size)).to(\"cuda\")\n",
    "attn_effects_cache = torch.zeros((model.config.num_hidden_layers, model.config.hidden_size)).to(\"cuda\")\n",
    "\n",
    "def attrPatching(fullPrompt, gold):\n",
    "    attn_layer_cache_prompt = {}\n",
    "    mlp_layer_cache_prompt = {}\n",
    "    \n",
    "    attn_layer_cache_patch = {}\n",
    "    mlp_layer_cache_patch = {}\n",
    "    if (gold == 'Yes'):\n",
    "        predictionExample = fullPrompt[fullPrompt[:-2].rfind(':')+1:-2].strip()\n",
    "        patch = og[og[sType] == predictionExample][f\"ng-{sType}\"].iloc[0]\n",
    "        patchPrompt = fullPrompt.replace(predictionExample, patch)\n",
    "    else:\n",
    "        patchPrompt = fullPrompt\n",
    "        patch = fullPrompt[fullPrompt[:-2].rfind(':')+1:-2].strip()\n",
    "        predictionExample = og[og[f\"ng-{sType}\"] == patch][sType].iloc[0]\n",
    "        fullPrompt = patchPrompt.replace(patch, predictionExample)\n",
    "        gold = \"Yes\"\n",
    "\n",
    "    notGold = \"No\"\n",
    "    gold = model.tokenizer(gold)[\"input_ids\"]\n",
    "    notGold = model.tokenizer(notGold)[\"input_ids\"]\n",
    "    with model.trace(fullPrompt, scan=False, validate=False) as tracer:\n",
    "        for layer in range(len(model.model.layers)):\n",
    "            self_attn = model.model.layers[layer].self_attn.o_proj.output\n",
    "            mlp = model.model.layers[layer].mlp.down_proj.output\n",
    "        \n",
    "            attn_layer_cache_prompt[layer] = {\"forward\": self_attn.detach().save(), \"backward\": self_attn.grad.detach().save()}\n",
    "            mlp_layer_cache_prompt[layer] = {\"forward\": mlp.detach().save(), \"backward\": mlp.grad.detach().save()}\n",
    "        \n",
    "        logits = model.lm_head.output[:, -1, notGold] - model.lm_head.output[:, -1, gold]\n",
    "        loss = logits.sum()\n",
    "        loss.backward(retain_graph=False)\n",
    "    \n",
    "  \n",
    "    with model.trace(patchPrompt, scan=False, validate=False) as tracer:\n",
    "        for layer in range(len(model.model.layers)):\n",
    "            self_attn = model.model.layers[layer].self_attn.o_proj.output\n",
    "            mlp = model.model.layers[layer].mlp.down_proj.output\n",
    "    \n",
    "            attn_layer_cache_patch[layer] = {\"forward\": self_attn.detach().save()}\n",
    "            mlp_layer_cache_patch[layer] = {\"forward\": mlp.detach().save()}\n",
    "    \n",
    "    for layer in range(len(model.model.layers)):\n",
    "        mlp_effects = mlp_layer_cache_prompt[layer][\"backward\"].value * (mlp_layer_cache_patch[layer][\"forward\"].value - mlp_layer_cache_prompt[layer][\"forward\"].value)\n",
    "        attn_effects = attn_layer_cache_prompt[layer][\"backward\"].value * (attn_layer_cache_patch[layer][\"forward\"].value - attn_layer_cache_prompt[layer][\"forward\"].value)\n",
    "    \n",
    "        mlp_effects = mlp_effects[:, -1, :] # batch, token, hidden_states\n",
    "        attn_effects = attn_effects[:, -1, :] # batch, token, hidden_states\n",
    "    \n",
    "        mlp_effects_cache[layer] += mlp_effects[0].to(mlp_effects_cache[layer].device)\n",
    "        attn_effects_cache[layer] += attn_effects[0].to(attn_effects_cache[layer].device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22148f63-f020-4298-9a51-79e61da8eecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, list, 'ita')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prompts), type(golds), sType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e05d076e-20c6-4f01-b82e-b942f98cee9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [01:03,  3.75s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt,gold \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mzip\u001b[39m(prompts, golds)):\n\u001b[0;32m----> 2\u001b[0m     attrPatching(prompt, gold)\n",
      "Cell \u001b[0;32mIn[20], line 37\u001b[0m, in \u001b[0;36mattrPatching\u001b[0;34m(fullPrompt, gold)\u001b[0m\n\u001b[1;32m     33\u001b[0m     loss \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     34\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward(retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m model\u001b[38;5;241m.\u001b[39mtrace(patchPrompt, scan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, validate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m tracer:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mlayers)):\n\u001b[1;32m     39\u001b[0m         self_attn \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mlayers[layer]\u001b[38;5;241m.\u001b[39mself_attn\u001b[38;5;241m.\u001b[39mo_proj\u001b[38;5;241m.\u001b[39moutput\n",
      "File \u001b[0;32m/mnt/align4_drive/arunas/miniconda3/envs/broca/lib/python3.12/site-packages/nnsight/contexts/Runner.py:49\u001b[0m, in \u001b[0;36mRunner.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__exit__\u001b[39m(exc_type, exc_val, exc_tb)\n",
      "File \u001b[0;32m/mnt/align4_drive/arunas/miniconda3/envs/broca/lib/python3.12/site-packages/nnsight/contexts/Tracer.py:67\u001b[0m, in \u001b[0;36mTracer.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc_val, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_val\n\u001b[0;32m---> 67\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39minterleave(\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39m_execute,\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph,\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batched_input,\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs,\n\u001b[1;32m     72\u001b[0m )\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39mtracing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/align4_drive/arunas/miniconda3/envs/broca/lib/python3.12/site-packages/nnsight/models/NNsightModel.py:255\u001b[0m, in \u001b[0;36mNNsight.interleave\u001b[0;34m(self, fn, intervention_graph, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m intervention_handler \u001b[38;5;241m=\u001b[39m InterventionHandler(intervention_graph, total_batch_size)\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m HookHandler(\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model,\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28mlist\u001b[39m(intervention_graph\u001b[38;5;241m.\u001b[39margument_node_names\u001b[38;5;241m.\u001b[39mkeys()),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    253\u001b[0m     ),\n\u001b[1;32m    254\u001b[0m ):\n\u001b[0;32m--> 255\u001b[0m     output \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    257\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# gc.collect()\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# torch.cuda.empty_cache()\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/align4_drive/arunas/miniconda3/envs/broca/lib/python3.12/site-packages/nnsight/models/mixins/Generation.py:21\u001b[0m, in \u001b[0;36mGenerationMixin._execute\u001b[0;34m(self, prepared_inputs, generate, *args, **kwargs)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generate:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_generate(prepared_inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_forward(prepared_inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/mnt/align4_drive/arunas/miniconda3/envs/broca/lib/python3.12/site-packages/nnsight/models/LanguageModel.py:276\u001b[0m, in \u001b[0;36mLanguageModel._execute_forward\u001b[0;34m(self, prepared_inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_execute_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, prepared_inputs: Any, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    274\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mparameters())\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model(\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprepared_inputs\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    280\u001b[0m     )\n",
      "File \u001b[0;32m/mnt/align4_drive/arunas/miniconda3/envs/broca/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/mnt/align4_drive/arunas/miniconda3/envs/broca/lib/python3.12/site-packages/torch/nn/modules/module.py:1561\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1558\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1559\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1561\u001b[0m result \u001b[38;5;241m=\u001b[39m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1563\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1564\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1565\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1566\u001b[0m     ):\n\u001b[1;32m   1567\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/align4_drive/arunas/miniconda3/envs/broca/lib/python3.12/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/mnt/align4_drive/arunas/miniconda3/envs/broca/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:1176\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1173\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1176\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[1;32m   1177\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1178\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   1179\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   1180\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m   1181\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m   1182\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m   1183\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1184\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1185\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1186\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[1;32m   1187\u001b[0m )\n\u001b[1;32m   1189\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/mnt/align4_drive/arunas/miniconda3/envs/broca/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/mnt/align4_drive/arunas/miniconda3/envs/broca/lib/python3.12/site-packages/torch/nn/modules/module.py:1561\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1558\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1559\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1561\u001b[0m result \u001b[38;5;241m=\u001b[39m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1563\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1564\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1565\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1566\u001b[0m     ):\n\u001b[1;32m   1567\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/align4_drive/arunas/miniconda3/envs/broca/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:1019\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1008\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1009\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1010\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1016\u001b[0m         cache_position,\n\u001b[1;32m   1017\u001b[0m     )\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1019\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m decoder_layer(\n\u001b[1;32m   1020\u001b[0m         hidden_states,\n\u001b[1;32m   1021\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mcausal_mask,\n\u001b[1;32m   1022\u001b[0m         position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   1023\u001b[0m         past_key_value\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m   1024\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1025\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m   1026\u001b[0m         cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[1;32m   1027\u001b[0m     )\n\u001b[1;32m   1029\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/mnt/align4_drive/arunas/miniconda3/envs/broca/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/mnt/align4_drive/arunas/miniconda3/envs/broca/lib/python3.12/site-packages/torch/nn/modules/module.py:1561\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1558\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1559\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1561\u001b[0m result \u001b[38;5;241m=\u001b[39m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1563\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1564\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1565\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1566\u001b[0m     ):\n\u001b[1;32m   1567\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/align4_drive/arunas/miniconda3/envs/broca/lib/python3.12/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/mnt/align4_drive/arunas/miniconda3/envs/broca/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:740\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    737\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    739\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 740\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(\n\u001b[1;32m    741\u001b[0m     hidden_states\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[1;32m    742\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m    743\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m    744\u001b[0m     past_key_value\u001b[38;5;241m=\u001b[39mpast_key_value,\n\u001b[1;32m    745\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    746\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m    747\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    749\u001b[0m )\n\u001b[1;32m    750\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    752\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/align4_drive/arunas/miniconda3/envs/broca/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/mnt/align4_drive/arunas/miniconda3/envs/broca/lib/python3.12/site-packages/torch/nn/modules/module.py:1561\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1558\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1559\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1561\u001b[0m result \u001b[38;5;241m=\u001b[39m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1563\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1564\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1565\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1566\u001b[0m     ):\n\u001b[1;32m   1567\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/align4_drive/arunas/miniconda3/envs/broca/lib/python3.12/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/mnt/align4_drive/arunas/miniconda3/envs/broca/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:640\u001b[0m, in \u001b[0;36mLlamaSdpaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position)\u001b[0m\n\u001b[1;32m    637\u001b[0m bsz, q_len, _ \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m    639\u001b[0m query_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_proj(hidden_states)\n\u001b[0;32m--> 640\u001b[0m key_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_proj(hidden_states)\n\u001b[1;32m    641\u001b[0m value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(hidden_states)\n\u001b[1;32m    643\u001b[0m query_states \u001b[38;5;241m=\u001b[39m query_states\u001b[38;5;241m.\u001b[39mview(bsz, q_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/mnt/align4_drive/arunas/miniconda3/envs/broca/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/mnt/align4_drive/arunas/miniconda3/envs/broca/lib/python3.12/site-packages/torch/nn/modules/module.py:1561\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1558\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1559\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1561\u001b[0m result \u001b[38;5;241m=\u001b[39m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1563\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1564\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1565\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1566\u001b[0m     ):\n\u001b[1;32m   1567\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/align4_drive/arunas/miniconda3/envs/broca/lib/python3.12/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/mnt/align4_drive/arunas/miniconda3/envs/broca/lib/python3.12/site-packages/bitsandbytes/nn/modules.py:426\u001b[0m, in \u001b[0;36mLinear4bit.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    424\u001b[0m inp_dtype \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 426\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_dtype)\n\u001b[1;32m    428\u001b[0m bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_dtype)\n\u001b[1;32m    429\u001b[0m out \u001b[38;5;241m=\u001b[39m bnb\u001b[38;5;241m.\u001b[39mmatmul_4bit(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mt(), bias\u001b[38;5;241m=\u001b[39mbias, quant_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mquant_state)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for prompt,gold in tqdm(zip(prompts, golds)):\n",
    "    attrPatching(prompt, gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53eb8fe1-b776-4410-bec9-fdb65918b25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_effects_cache /= len(prompts)\n",
    "attn_effects_cache /= len(prompts)\n",
    "\n",
    "mlp_effects_cache = torch.nan_to_num(mlp_effects_cache)\n",
    "attn_effects_cache = torch.nan_to_num(attn_effects_cache)\n",
    "\n",
    "flattened_effects_cache = mlp_effects_cache.view(-1)\n",
    "top_neurons = flattened_effects_cache.topk(k=40)\n",
    "two_d_indices = torch.cat((((top_neurons[1] // mlp_effects_cache.shape[1]).unsqueeze(1)), ((top_neurons[1] % mlp_effects_cache.shape[1]).unsqueeze(1))), dim=1)\n",
    "\n",
    "with open(f'{PREFIX}/broca/llama/llama-attr-patch-scripts/mlp/{sType}.pkl', 'wb') as f:\n",
    "    pickle.dump(two_d_indices, f)\n",
    "\n",
    "flattened_effects_cache = attn_effects_cache.view(-1)\n",
    "top_neurons = flattened_effects_cache.topk(k=40)\n",
    "two_d_indices = torch.cat((((top_neurons[1] // attn_effects_cache.shape[1]).unsqueeze(1)), ((top_neurons[1] % attn_effects_cache.shape[1]).unsqueeze(1))), dim=1)\n",
    "\n",
    "with open(f'{PREFIX}/broca/llama/llama-attr-patch-scripts/attn/{sType}.pkl', 'wb') as f:\n",
    "    pickle.dump(two_d_indices, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
