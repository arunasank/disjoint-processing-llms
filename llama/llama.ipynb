{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e015136-bbc6-437d-9f9a-875407cc43a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_map = {'model.embed_tokens': 0,\n",
    "'model.layers.0': 0,\n",
    "'model.layers.1': 0,\n",
    "'model.layers.2': 0,\n",
    "'model.layers.3': 0,\n",
    "'model.layers.4': 0,\n",
    "'model.layers.5': 0,\n",
    "'model.layers.6': 0,\n",
    "'model.layers.7': 0,\n",
    "'model.layers.8': 0,\n",
    "'model.layers.9': 0,\n",
    "'model.layers.10': 0,\n",
    "'model.layers.11': 0,\n",
    "'model.layers.12': 0,\n",
    "'model.layers.13': 0,\n",
    "'model.layers.14': 0,\n",
    "'model.layers.15': 0,\n",
    "'model.layers.16': 0,\n",
    "'model.layers.17': 0,\n",
    "'model.layers.18': 0,\n",
    "'model.layers.19': 0,\n",
    "'model.layers.20': 0,\n",
    "'model.layers.21': 0,\n",
    "'model.layers.22': 0,\n",
    "'model.layers.23': 0,\n",
    "'model.layers.24': 0,\n",
    "'model.layers.25': 0,\n",
    "'model.layers.26': 0,\n",
    "'model.layers.27': 0,\n",
    "'model.layers.28': 0,\n",
    "'model.layers.29': 0,\n",
    "'model.layers.30': 0,\n",
    "'model.layers.31': 0,\n",
    "'model.layers.32.self_attn': 0,\n",
    "'model.layers.32.mlp.gate_proj': 0,\n",
    "'model.layers.32.mlp.up_proj': 1,\n",
    "'model.layers.32.mlp.down_proj': 1,\n",
    "'model.layers.32.mlp.act_fn': 1,\n",
    "'model.layers.32.input_layernorm': 1,\n",
    "'model.layers.32.post_attention_layernorm': 1,\n",
    "'model.layers.33': 1,\n",
    "'model.layers.34': 1,\n",
    "'model.layers.35': 1,\n",
    "'model.layers.36': 1,\n",
    "'model.layers.37': 1,\n",
    "'model.layers.38': 1,\n",
    "'model.layers.39': 1,\n",
    "'model.layers.40': 1,\n",
    "'model.layers.41': 1,\n",
    "'model.layers.42': 1,\n",
    "'model.layers.43': 1,\n",
    "'model.layers.44': 1,\n",
    "'model.layers.45': 1,\n",
    "'model.layers.46': 1,\n",
    "'model.layers.47': 1,\n",
    "'model.layers.48': 1,\n",
    "'model.layers.49': 1,\n",
    "'model.layers.50': 1,\n",
    "'model.layers.51': 1,\n",
    "'model.layers.52': 1,\n",
    "'model.layers.53': 1,\n",
    "'model.layers.54': 1,\n",
    "'model.layers.55': 1,\n",
    "'model.layers.56': 1,\n",
    "'model.layers.57': 1,\n",
    "'model.layers.58.self_attn': 1,\n",
    "'model.layers.58.mlp.gate_proj': 1,\n",
    "'model.layers.58.mlp.up_proj': 0,\n",
    "'model.layers.58.mlp.down_proj': 0,\n",
    "'model.layers.58.mlp.act_fn': 0,\n",
    "'model.layers.58.input_layernorm': 0,\n",
    "'model.layers.58.post_attention_layernorm': 0,\n",
    "'model.layers.59': 0,\n",
    "'model.layers.60': 0,\n",
    "'model.layers.61': 0,\n",
    "'model.layers.62': 0,\n",
    "'model.layers.63': 0,\n",
    "'model.layers.64': 0,\n",
    "'model.layers.65': 0,\n",
    "'model.layers.66': 0,\n",
    "'model.layers.67': 0,\n",
    "'model.layers.68': 1,\n",
    "'model.layers.69': 1,\n",
    "'model.layers.70': 1,\n",
    "'model.layers.71': 1,\n",
    "'model.layers.72': 1,\n",
    "'model.layers.73': 1,\n",
    "'model.layers.74': 1,\n",
    "'model.layers.75': 1,\n",
    "'model.layers.76': 1,\n",
    "'model.layers.77': 1,\n",
    "'model.layers.78': 1,\n",
    "'model.layers.79': 1,\n",
    "'model.norm': 1,\n",
    "'lm_head': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a26a4a5e-6b5f-4eeb-bfd0-aea8c2fc9bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "icl_grammars.py\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e0213955001485e8b915e1381f060ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('icl_grammars.py')\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForCausalLM, AutoConfig,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "import bitsandbytes\n",
    "from accelerate import infer_auto_device_map\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset, load_dataset\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# from transformers.utils import logging as hf_logging\n",
    "# hf_logging.disable_progress_bar()\n",
    "\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# torch.set_default_dtype(torch.)\n",
    "\n",
    "LLAMA_PATH = '/home/gridsan/arunas/broca/llama'\n",
    "TOKENIZER_PATH = '/home/gridsan/arunas/broca/llama'\n",
    "# LLAMA_PATH = '/home/gridsan/arunas/models/mistralai/Mistral-7B-v0.1/'\n",
    "# TOKENIZER_PATH = '/home/gridsan/arunas/tokenizers/mistralai/Mistral-7B-v0.1/'\n",
    "\n",
    "model_path = f\"{LLAMA_PATH}/llama-model\"\n",
    "tokenizer_path = f'{TOKENIZER_PATH}/llama-tokenizer'\n",
    "config = AutoConfig.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    tokenizer_path, config=config, device_map=device_map, padding_side=\"left\"\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# model = AutoModelForCausalLM.from_pretrained(f'{model_path}', device_map=device_map, quantization_config=nf4_config)\n",
    "model = AutoModelForCausalLM.from_pretrained(f'{model_path}', device_map=device_map, load_in_4bit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd4c4a86-1f3b-4975-9924-1a5a033ca745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------Model loaded------------------------------\n",
      "-------------------------Device map--------------------------------\n",
      "{'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 0, 'model.layers.9': 0, 'model.layers.10': 0, 'model.layers.11': 0, 'model.layers.12': 0, 'model.layers.13': 0, 'model.layers.14': 0, 'model.layers.15': 0, 'model.layers.16': 0, 'model.layers.17': 0, 'model.layers.18': 0, 'model.layers.19': 0, 'model.layers.20': 0, 'model.layers.21': 0, 'model.layers.22': 0, 'model.layers.23': 0, 'model.layers.24': 0, 'model.layers.25.self_attn': 0, 'model.layers.25.mlp.gate_proj': 0, 'model.layers.25.mlp.up_proj': 0, 'model.layers.25.mlp.down_proj': 1, 'model.layers.25.mlp.act_fn': 1, 'model.layers.25.input_layernorm': 1, 'model.layers.25.post_attention_layernorm': 1, 'model.layers.26': 1, 'model.layers.27': 1, 'model.layers.28': 1, 'model.layers.29': 1, 'model.layers.30': 1, 'model.layers.31': 1, 'model.layers.32': 1, 'model.layers.33': 1, 'model.layers.34': 1, 'model.layers.35': 1, 'model.layers.36': 1, 'model.layers.37': 1, 'model.layers.38': 1, 'model.layers.39': 1, 'model.layers.40': 1, 'model.layers.41': 1, 'model.layers.42': 1, 'model.layers.43': 1, 'model.layers.44': 1, 'model.layers.45': 1, 'model.layers.46': 1, 'model.layers.47': 1, 'model.layers.48': 1, 'model.layers.49': 1, 'model.layers.50': 1, 'model.layers.51': 1, 'model.layers.52': 1, 'model.layers.53': 1, 'model.layers.54': 1, 'model.layers.55': 1, 'model.layers.56': 1, 'model.layers.57': 1, 'model.layers.58.self_attn': 1, 'model.layers.58.mlp.gate_proj': 1, 'model.layers.58.mlp.up_proj': 'cpu', 'model.layers.58.mlp.down_proj': 'cpu', 'model.layers.58.mlp.act_fn': 'cpu', 'model.layers.58.input_layernorm': 'cpu', 'model.layers.58.post_attention_layernorm': 'cpu', 'model.layers.59': 'cpu', 'model.layers.60': 'cpu', 'model.layers.61': 'cpu', 'model.layers.62': 'cpu', 'model.layers.63': 'cpu', 'model.layers.64': 'cpu', 'model.layers.65': 'cpu', 'model.layers.66': 'cpu', 'model.layers.67': 'cpu', 'model.layers.68': 'cpu', 'model.layers.69': 'cpu', 'model.layers.70': 'cpu', 'model.layers.71': 'cpu', 'model.layers.72': 'cpu', 'model.layers.73': 'cpu', 'model.layers.74': 'cpu', 'model.layers.75': 'cpu', 'model.layers.76': 'cpu', 'model.layers.77': 'cpu', 'model.layers.78': 'cpu', 'model.layers.79': 'cpu', 'model.norm': 'cpu', 'lm_head': 'cpu'}\n"
     ]
    }
   ],
   "source": [
    "print('-------------------------Model loaded------------------------------')\n",
    "\n",
    "device_map = infer_auto_device_map(model)\n",
    "print('-------------------------Device map--------------------------------')\n",
    "\n",
    "print(device_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038df62f-2a70-4b60-a048-38999f908702",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
