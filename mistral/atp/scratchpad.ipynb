{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e733086-cbbd-4640-92e0-d6ce61db719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForCausalLM, AutoConfig,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "import bitsandbytes\n",
    "from accelerate import infer_auto_device_map\n",
    "from nnsight import LanguageModel\n",
    "import sys\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from datasets import Dataset, load_dataset\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "import yaml\n",
    "import argparse\n",
    "import numpy as np\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "\n",
    "# parser.add_argument('--config', type=str, help='path to the model training config file, found in broca/configs')\n",
    "# parser.add_argument('--stype', type=int, help='grammar structure col number, found in broca/data-gen')\n",
    "\n",
    "# args = parser.parse_args()\n",
    "# with open(args.config, 'r') as f:\n",
    "#     config = yaml.safe_load(f)\n",
    "\n",
    "args = { \"config\": \"/mnt/align4_drive/arunas/broca/configs/mistral-icl-config\", \"stype\": 7 }\n",
    "with open(args[\"config\"], 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "PREFIX = config[\"prefix\"]\n",
    "MODEL_NAME = config[\"model_name\"]\n",
    "MODEL_PATH = config[\"model_path\"]\n",
    "ABLATION = config[\"ablation\"]\n",
    "DATA_PATH = config[\"data_path\"]\n",
    "NUM_DEMONSTRATIONS = config[\"num_dems\"]\n",
    "BATCH_SIZE = config[\"batch_size\"]\n",
    "FINAL_CSV_SUBPATH = config[\"final_csv_subpath\"]\n",
    "MAX_LEN = 0\n",
    "\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "df = pd.read_csv(f'{DATA_PATH}')\n",
    "gCols = [col for col in list(df.columns) if not 'ng' in col]\n",
    "# col = gCols[args.stype]\n",
    "\n",
    "col = gCols[args[\"stype\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88b19200-13bb-4419-b26d-11b68be01d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{DATA_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4791cf4-8770-4933-8a42-39e48f316717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABLATION!\n",
      "ablating mlp  en\n",
      "before top k torch.Size([32, 4096])\n",
      "ablating attn  en\n",
      "before top k torch.Size([32, 4096])\n"
     ]
    }
   ],
   "source": [
    "if (ABLATION):\n",
    "    print('ABLATION!')\n",
    "    # model_config = AutoConfig.from_pretrained(MODEL_PATH)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, device_map=\"auto\", padding_side=\"left\")\n",
    "    \n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model = LanguageModel(MODEL_PATH, device_map='auto') # Load the model\n",
    "    \n",
    "    device_map = infer_auto_device_map(model)\n",
    "    MEAN_ABLATION = config[\"mean_ablation\"]\n",
    "    MEAN_PICKLES_PATH = config[\"mean_pickles_path\"]\n",
    "    MEAN_PICKLES_SUBPATH = config[\"mean_pickles_subpath\"]\n",
    "    PATCH_PICKLES_PATH = config[\"patch_pickles_path\"]\n",
    "    PATCH_PICKLES_SUBPATH = config[\"patch_pickles_subpath\"]\n",
    "    def retrieve_topK(col, component, topK):\n",
    "        with open(f'{PATCH_PICKLES_PATH}/{component}/{PATCH_PICKLES_SUBPATH}/{col}.pkl', 'rb') as f:\n",
    "            print(f'ablating {component} ', col)\n",
    "            component_cache = pickle.load(f)\n",
    "            print('before top k', component_cache.shape)\n",
    "            component_cache = component_cache.cpu()\n",
    "            flattened_effects_cache = component_cache.view(-1)\n",
    "            top_neurons = flattened_effects_cache.topk(k=int(topK * flattened_effects_cache.shape[-1]))\n",
    "            two_d_indices = torch.cat((((top_neurons[1] // component_cache.shape[1]).unsqueeze(1)), ((top_neurons[1] % component_cache.shape[1]).unsqueeze(1))), dim=1)            \n",
    "            df = pd.DataFrame(two_d_indices, columns=['layer', 'neuron'])\n",
    "        return df\n",
    "\n",
    "    def ablation_cache(col, component):\n",
    "        global MAX_LEN\n",
    "        df = retrieve_topK(col, component, 0.01)\n",
    "        with open(f'{MEAN_PICKLES_PATH}/{component}/{MEAN_PICKLES_SUBPATH}/{col}.pkl', 'rb') as mf:\n",
    "            component_cache = pickle.load(mf)\n",
    "            component_cache = component_cache.cpu()\n",
    "            comp_values = []\n",
    "            for idx, row in df.iterrows():\n",
    "                comp_values.append(list(component_cache[row['layer'], :, row['neuron']].numpy().flatten()))\n",
    "            MAX_LEN = len(comp_values[0])\n",
    "            df['values'] = comp_values\n",
    "        return df\n",
    "\n",
    "    with torch.no_grad():\n",
    "        mlp_ablate = ablation_cache(col, 'mlp')\n",
    "        attn_ablate = ablation_cache(col, 'attn')\n",
    "else:\n",
    "    model_config = AutoConfig.from_pretrained(MODEL_PATH)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, config=model_config, device_map=\"auto\", padding_side=\"left\")\n",
    "    \n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model = AutoModelForCausalLM.from_pretrained(MODEL_PATH, config=model_config, device_map='auto') # Load the model\n",
    "    \n",
    "    device_map = infer_auto_device_map(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6da6fde-7923-47fb-af34-304667c1e379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_answer(text):\n",
    "    answers = []\n",
    "    for t in text:\n",
    "        ans = t.split(\"A:\")[-1].strip()\n",
    "        answers.append(ans)\n",
    "    return answers\n",
    "\n",
    "def construct_prompt(train_dataset, num_demonstrations):\n",
    "    assert num_demonstrations > 0\n",
    "    prompt = ''\n",
    "    train_examples = train_dataset.shuffle(seed=42).select(range(num_demonstrations))\n",
    "    for exemplar_num in range(num_demonstrations):\n",
    "        train_example = train_examples[exemplar_num]\n",
    "        use_bad_sentence = random.choice([True, False])\n",
    "        exemplar = \"Q: Is this sentence grammatical? Yes or No: \"\n",
    "        if use_bad_sentence:\n",
    "            exemplar += train_example[\"ng-\" + col]\n",
    "            exemplar += \"\\nA: No\"\n",
    "        else:\n",
    "            exemplar += train_example[col]\n",
    "            exemplar += \"\\nA: Yes\"\n",
    "        exemplar += \"\\n\\n\"\n",
    "        prompt += exemplar\n",
    "    return prompt\n",
    "\n",
    "def compute_accuracy(preds, golds):\n",
    "    print(len(preds), len(golds))\n",
    "    assert len(preds) == len(golds)\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for pred, gold in zip(preds, golds):\n",
    "        if pred == gold:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_aligned_words_measures(texts: str, \n",
    "                               answers: str,\n",
    "                               measure: str,\n",
    "                               model: GPT2LMHeadModel, \n",
    "                               tokenizer: GPT2Tokenizer) -> list[str]:\n",
    "    if measure not in {'prob', 'surp'}:\n",
    "        sys.stderr.write(f\"{measure} not recognized\\n\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    datas = []\n",
    "    for t in range(len(texts)):\n",
    "        text = f'{texts[t]} {answers[t]}'\n",
    "        data = []\n",
    "    \n",
    "        ids = tokenizer(text, return_tensors='pt').to('cuda')\n",
    "        input_ids = ids.input_ids.flatten().data\n",
    "        target_ids = ids.input_ids[:,1:]\n",
    "    \n",
    "        # get output\n",
    "        logits = model(**ids).logits\n",
    "        output = torch.nn.functional.log_softmax(logits, dim=-1)\n",
    "        if measure == 'surp':\n",
    "            output = -(output/torch.log(torch.tensor(2.0)))\n",
    "        else:\n",
    "            output = torch.exp(output)\n",
    "    \n",
    "        # get by token measures \n",
    "        target_measures = output[:,:-1, :]\n",
    "        # use gather to get the output for each target item in the batch\n",
    "        target_measures = target_measures.gather(-1,\n",
    "                                 target_ids.unsqueeze(2)).flatten().tolist()\n",
    "        \n",
    "        tokens = tokenizer.convert_ids_to_tokens(input_ids)[1:]\n",
    "        words = text.split(' ')\n",
    "    \n",
    "        # A lil loop to force align words \n",
    "        current_word = words.pop(0)\n",
    "        current_token = tokens.pop(0).replace('▁', '')\n",
    "        measure = 0\n",
    "        while len(data) != len(text.split(' ')) and len(target_measures) > 0:\n",
    "            if current_word == current_token:\n",
    "                data.append((current_word, measure))\n",
    "                measure = 0\n",
    "                if words:\n",
    "                    current_word = words.pop(0)\n",
    "                    current_token = tokens.pop(0).replace('▁', '')\n",
    "                    measure += target_measures.pop(0)\n",
    "            else:\n",
    "                measure += target_measures.pop(0)\n",
    "                current_token += tokens.pop(0).replace('▁', '')\n",
    "                data.append((current_token, measure))\n",
    "        datas.append(data)\n",
    "    return datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b910329-cadd-4ba7-8214-a59087d563b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ita', 'ita-r-1-null_subject', 'ita-r-2-subordinate', 'ita-r-3-passive',\n",
      "       'ita-u-1-negation', 'ita-u-2-invert', 'ita-u-3-gender', 'en',\n",
      "       'en-r-1-subordinate', 'en-r-2-passive', 'en-u-1-negation',\n",
      "       'en-u-2-inversion', 'en-u-3-qsubordinate', 'en-u-4-wh', 'it',\n",
      "       'it-r-1-null_subject', 'it-r-2-passive', 'it-r-3-subordinate',\n",
      "       'it-u-1-negation', 'it-u-2-invert', 'it-u-3-gender', 'jp-r-1-sov',\n",
      "       'jap-r-1-sov', 'jp-r-2-passive', 'jap-r-2-passive',\n",
      "       'jp-r-3-subordinate', 'jap-r-3-subordinate', 'jp-u-1-negation',\n",
      "       'jap-u-1-negation', 'jp-u-2-invert', 'jap-u-2-invert',\n",
      "       'jp-u-3-past-tense', 'jap-u-3-past-tense', 'ng-ita',\n",
      "       'ng-ita-r-1-null_subject', 'ng-ita-r-2-subordinate',\n",
      "       'ng-ita-r-3-passive', 'ng-ita-u-1-negation', 'ng-ita-u-2-invert',\n",
      "       'ng-ita-u-3-gender', 'ng-en', 'ng-en-r-1-subordinate',\n",
      "       'ng-en-r-2-passive', 'ng-en-u-1-negation', 'ng-en-u-2-inversion',\n",
      "       'ng-en-u-3-qsubordinate', 'ng-en-u-4-wh', 'ng-it',\n",
      "       'ng-it-r-1-null_subject', 'ng-it-r-2-passive', 'ng-it-r-3-subordinate',\n",
      "       'ng-it-u-1-negation', 'ng-it-u-2-invert', 'ng-it-u-3-gender',\n",
      "       'ng-jp-r-1-sov', 'ng-jap-r-1-sov', 'ng-jp-r-2-passive'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "golds = []\n",
    "\n",
    "f = pd.DataFrame(columns=[\"type\", \"prompt\", \"q\", \"prediction\", \"gold\", \"surprisal\", \"int-grad\"])\n",
    "f['type'] = 'test'\n",
    "g = pd.DataFrame(columns=['accuracy', 'type'])\n",
    "datasets = {}\n",
    "np.random.seed(42)\n",
    "print(df.columns)\n",
    "datasets[col] = Dataset.from_pandas(pd.DataFrame(df[[col, 'ng-' + col]].copy())).train_test_split(test_size=0.5)\n",
    "def get_master_prompt(lang):\n",
    "    en_verbs = [\"affirms\", \"bring\", \"brings\", \"carries\", \"carry\", \"climb\", \"climbs\", \"eat\", \"eats\", \"hold\", \"holds\", \"knows\", \"notices\", \"read\", \"reads\", \"says\", \"sees\", \"take\", \"takes\"]\n",
    "    en_verbs_past = [\"affirmed\", \"brought\", \"carried\", \"climbed\", \"ate\", \"held\", \"knew\", \"noticed\", \"read\", \"said\", \"saw\", \"took\"]\n",
    "    en_verbs_infinitive = [\"to affirm\", \"to bring\", \"to carry\", \"to climb\", \"to eat\", \"to hold\", \"to know\", \"to notice\", \"to read\", \"to say\", \"to see\", \"to take\"]\n",
    "    en_verbs_passive = [\"affirmed\", \"brought\", \"carried\", \"climbed\", \"eaten\", \"held\", \"known\", \"noticed\", \"read\", \"said\", \"seen\", \"taken\"]\n",
    "    en_nouns = ['author', 'banana', 'biscuit', 'book', 'bottle', 'box', 'boy', 'bulb', 'cap', 'cat', 'chalk', 'chapter', 'cucumber', 'cup', 'dog', 'fish', 'fruit', 'girl', 'hill', 'man', 'meal', 'mountain', 'mouse', 'newspaper', 'pear', 'pizza', 'poem', 'poet', 'rock', 'roof', 'speaker', 'staircase', 'story', 'teacher', 'toy', 'tree', 'woman', 'writer']\n",
    "    en_nouns_plural = ['authors', 'boys', 'cats', 'dogs', 'girls', 'men', 'poets', 'speakers', 'teachers', 'women', 'writers']\n",
    "    proper_nouns = ['Gomu', 'Harry', 'John', 'Leela', 'Maria', 'Sheela', 'Tom']\n",
    "    \n",
    "    ita_verbs = ['legge', 'leggono', 'mangia', 'mangiano', 'porta', 'portano', 'prende', 'prendono',\n",
    "                'salgono', 'scala', 'tengono', 'tiene', 'vede', 'dice', 'osserva', 'sa', 'afferma']\n",
    "    ita_verbs_past = ['è letto', 'è mangiato', 'è portato', 'è preso', 'è scalata', 'è scalato', 'è tenuto', 'è salito']\n",
    "    ita_verbs_infinitive = ['leggere', 'magiare', 'portare', 'prendere', 'scalare', 'tenere', 'salire']\n",
    "    ita_nouns = ['albero', 'autore', 'banana', 'biscotto', 'bottiglia', 'cane', 'capitolo', 'cappello', 'cetriolo', 'collina', 'donna', 'frutta', 'gatto', 'gesso', 'giocattolo', 'giornale', 'insegnante', 'lampadina', 'libro', 'montagna', 'oratorio', 'pasto', 'pera', 'pesce', 'pizza', 'poema', 'poeta', 'ragazza', 'ragazzo', 'roccia', 'scala', 'scatola', 'scrittore', 'storia', 'tazza', 'tetto', 'topo', 'uomo']\n",
    "    ita_nouns_plurals = ['alberi', 'autori', 'banane', 'biscotti', 'bottiglie', 'cani', 'capitoli', 'cappelli', 'cetrioli', 'colline', 'donne', 'frutta', 'gatti', 'gessi', 'giocattoli', 'giornali', 'insegnanti', 'lampadine', 'libri', 'montagne', 'oratori', 'pasti', 'pere', 'pesci', 'pizze', 'poemi', 'poeti', 'ragazze', 'ragazzi', 'rocce', 'scale', 'scatole', 'scrittori', 'storie', 'tazze', 'tetti', 'topi', 'uomini']\n",
    "    ita_nouns_la = [\"pera\", \"banana\", \"bottiglia\", \"scatola\", \"lampadina\", \"credenza\", \"tazza\", \"frutta\", \"ragazza\", \"collina\", \"montagna\", \"pizza\", \"roccia\", \"scala\", \"storia\", \"donna\"]\n",
    "    ita_nouns_lo = [\"scrittore\"]\n",
    "    ita_nouns_il = [\"biscotto\", \"libro\", \"ragazzo\", \"cappello\", \"gatto\", \"capitolo\", \"gesso\", \"cetriolo\", \"cane\", \"oratorio\", \"pesce\", \"pasto\", \"topo\", \"giornale\", \"poeta\", \"poema\", \"tetto\", \"giocattolo\"]\n",
    "    ita_nouns_gli = [\"scrittori\", \"uomini\", \"oratori\", \"insegnanti\", \"autori\"]\n",
    "    ita_nouns_i = [\"ragazzi\", \"gatti\", \"cani\", \"poeti\"]\n",
    "    ita_nouns_il_vowel = [\"uomo\", \"oratore\", \"insegnante\", \"albero\", \"autore\"]\n",
    "    ita_nouns_le = [\"donne\"]\n",
    "    \n",
    "    it_nouns_kon = ['author', 'biscuit', 'book', 'boy', 'cap', 'cat', 'chalk', 'chapter', 'cucumber', 'dog', 'fish', 'man', 'meal', 'mouse', 'newspaper', 'poet', 'rock', 'roof', 'speaker', 'teacher', 'toy', 'writer']\n",
    "    it_nouns_kar = ['banana', 'bottle', 'box', 'bulb', 'cabinet', 'cup', 'fruit', 'girl', 'hill', 'mountain', 'pear', 'pizza', 'poem', 'staircase', 'story', 'tree', 'woman']\n",
    "    it_nouns_kons = ['authors', 'boys', 'cats', 'dogs', 'men', 'poets', 'speakers', 'teachers', 'writers']\n",
    "    it_nouns_kars = [\"girls\", \"women\"]\n",
    "    jp_nouns = [\"梨\", \"著者\", \"バナナ\", \"ビスケット\", \"本\", \"ボトル\", \"箱\", \"男の子\", \"電球\", \"帽子\", \"猫\", \"章\", \"白亜\", \"コップ\", \"胡瓜\", \"犬\", \"魚\", \"果物\", \"女の子\", \"丘\", \"男\", \"食事\", \"山\", \"マウス\", \"新聞\", \"麺\", \"詩人\", \"詩\", \"岩石\", \"屋根\", \"スピーカー\", \"階段\", \"小説\", \"先生\", \"玩具\", \"木\", \"女\", \"著者\", \"ピザ\", \"梨\", \"著者\", \"バナナ\", \"ビスケット\", \"本\", \"ボトル\", \"箱\", \"男の子\", \"電球\", \"帽子\", \"猫\", \"章\", \"白亜\", \"コップ\", \"胡瓜\", \"犬\", \"魚\", \"果物\", \"女の子\", \"丘\", \"男性\", \"食事\", \"山\", \"マウス\", \"新聞\", \"麺\", \"詩人\", \"詩\", \"岩石\", \"屋根\", \"スピーカー\", \"階段\", \"小説\", \"先生\", \"玩具\", \"木\", \"女性\", \"著者\", \"ピザ\"]\n",
    "    jp_verbs = [\"食べる\",\"読む\",\"運ぶ\",\"のぼる\",\"とる\",\"持つ\",\"もたらす\", \"食べる\",\"読む\",\"運ぶ\",\"のぼる\",\"とる\",\"持つ\",\"もたらす\"]\n",
    "    jp_verbs_passive = [\"食べられる\", \"読まれる\", \"運ばれる\", \"のぼられる\", \"とられる\", \"持たれる\", \"持たれる\"]\n",
    "    jp_suffixes = [ \"は\", \"が\", \"を\", \"と\", \"に\", \"ない\", \"た\" ]\n",
    "    jp_proper_nouns = [\"シーラ\", \"ゴム\", \"ハリー\", \"ジョン\", \"リーラ\", \"マリア\", \"トム\"]\n",
    "\n",
    "    if 'en' == \"\".join(lang[:2]):\n",
    "        intro = \"We will give you examples of English sentences that follow or violate the rules of a shared grammar, along with labels 'Yes' or 'No'. You will then generate a label, 'Yes' or 'No', for a new unlabeled sentence that may follow or violate the same grammar rules.\"\n",
    "        # verbs = f\"\"\"The sentences may use verbs ({', '.join(en_verbs)});\"\"\"\n",
    "        # pastTenseVerbs = f\"\"\"or their corresponding past tense forms ({', '.join(en_verbs_past)});\"\"\" \n",
    "        # infinitiveVerbs = f\"\"\"infinitive forms ({', '.join(en_verbs_infinitive)});\"\"\"\n",
    "        # passiveVerbs = f\"\"\"or passive forms ({', '.join(en_verbs_passive)}).\"\"\"\n",
    "        # nouns = f\"\"\"The sentences may use nouns ({', '.join(set(en_nouns + en_nouns_plural))}) for the subjects and objects.\"\"\"\n",
    "        # properNouns = f\"\"\"The sentences may use proper nouns ({', '.join(set(proper_nouns))}).\"\"\"\n",
    "        # return f\"\"\"1.{intro}\\n2.{verbs} {pastTenseVerbs} {infinitiveVerbs} {passiveVerbs}\\n3.{nouns}\\n4.{properNouns}\"\"\"\n",
    "        return f\"{intro}\"\n",
    "\n",
    "    elif 'it' == \"\".join(lang[:2]) and (len(lang) <=2 or lang[2] != 'a'):\n",
    "        intro = \"We will give you examples of English sentences stylized to Italian syntax that follow or violate the rules of a shared grammar, along with labels 'Yes' or 'No'. You will then generate a label, 'Yes' or 'No', for a new unlabeled sentence that may follow or violate the same grammar rules.\"\n",
    "        # verbs = f\"\"\"The sentences may use verbs ({', '.join(en_verbs)});\"\"\"\n",
    "        # pastTenseVerbs = f\"\"\"or their corresponding past tense forms ({', '.join(en_verbs_past)});\"\"\" \n",
    "        # infinitiveVerbs = f\"\"\"infinitive forms ({', '.join(en_verbs_infinitive)});\"\"\"\n",
    "        # passiveVerbs = f\"\"\"or passive forms ({', '.join(en_verbs_passive)}).\"\"\"\n",
    "        # nouns = f\"\"\"The sentences may use nouns ({', '.join(set(en_nouns + en_nouns_plural))}) for the subjects and objects.\"\"\"\n",
    "        # properNouns = f\"\"\"The sentences may use proper nouns ({', '.join(set(proper_nouns))}).\"\"\"\n",
    "        gendered = f\"\"\"The nouns in the sentences have specific gender determiners - 'kar' (used by {', '.join(set(it_nouns_kar))}); 'kon' (used by {', '.join(set(it_nouns_kon))}); 'kars' (used by {', '.join(set(it_nouns_kars))}); 'kons' (used by {', '.join(set(it_nouns_kons))}).\"\"\"\n",
    "        # return f\"\"\"1.{intro}\\n2.{verbs} {pastTenseVerbs} {infinitiveVerbs} {passiveVerbs}\\n3.{nouns}\\n4.{properNouns}\\n5.{gendered}\"\"\"\n",
    "        return f\"1. {intro}\\n2. {gendered}\"\n",
    "    \n",
    "    elif 'ita' == \"\".join(lang[:3]):\n",
    "        intro = \"We will give you examples of Italian sentences that follow or violate the rules of a shared grammar, along with labels 'Yes' or 'No'. You will then generate a label, 'Yes' or 'No', for a new unlabeled sentence that may follow or violate the same grammar rules.\"\n",
    "        # verbs = f\"\"\"The sentences may use verbs ({', '.join(ita_verbs)});\"\"\"\n",
    "        # pastTenseVerbs = f\"\"\"or their corresponding past tense forms ({', '.join(ita_verbs_past)});\"\"\" \n",
    "        # infinitiveVerbs = f\"\"\"infinitive forms ({', '.join(ita_verbs_infinitive)});\"\"\"\n",
    "        # passiveVerbs = f\"\"\"or passive forms ({', '.join(ita_verbs_past)}).\"\"\"\n",
    "        # nouns = f\"\"\"The sentences may use nouns ({', '.join(set(ita_nouns + ita_nouns_plurals))}) for the subjects and objects.\"\"\"\n",
    "        # properNouns = f\"\"\"The sentences may use proper nouns ({', '.join(set(proper_nouns))}).\"\"\"\n",
    "        # gendered = f\"\"\"The nouns in the sentences have specific gender determiners - 'la' (used by {', '.join(set(ita_nouns_la))}); 'lo' (used by {', '.join(set(ita_nouns_lo))}); 'le' (used by {', '.join(set(ita_nouns_le))}); 'il' (used by {', '.join(set(ita_nouns_il))}, \"l'\" (used by {', '.join(set(ita_nouns_il_vowel))}); 'i' (used by {', '.join(set(ita_nouns_i))}, and 'gli' (used by {', '.join(set(ita_nouns_gli))}.\"\"\"\n",
    "        # return f\"\"\"1.{intro}\\n2.{verbs} {pastTenseVerbs} {infinitiveVerbs} {passiveVerbs}\\n3.{nouns}\\n4.{properNouns}\\n5.{gendered}\"\"\"\n",
    "        return f\"{intro}\"\n",
    "    \n",
    "    elif 'jap' == \"\".join(lang[:3]):\n",
    "        intro = \"We will give you examples of Japanese sentences that follow or violate the rules of a shared grammar, along with labels 'Yes' or 'No'. You will then generate a label, 'Yes' or 'No', for a new unlabeled sentence that may follow or violate the same grammar rules.\"\n",
    "        # verbs = f\"\"\"The sentences may use verbs ({', '.join(jp_verbs)});\"\"\"\n",
    "        # passiveVerbs = f\"\"\"or passive forms ({', '.join(jp_verbs_passive)}).\"\"\"\n",
    "        # nouns = f\"\"\"The sentences may use nouns ({', '.join(set(jp_nouns))}) for the subjects and objects.\"\"\"\n",
    "        # suffixes = f\"\"\"The sentences may use suffixes ({', '.join(set(jp_suffixes))}) along with subjects, objects or verbs.\"\"\"\n",
    "        # properNouns = f\"\"\"The sentences may use proper nouns ({', '.join(set(jp_proper_nouns))}).\"\"\"\n",
    "        # return f\"\"\"1.{intro}\\n2.{verbs} {passiveVerbs}\\n3.{nouns}\\n4.{properNouns}\\n5.{suffixes}\"\"\"\n",
    "        return f\"{intro}\"\n",
    "    \n",
    "    elif 'jp' == \"\".join(lang[:2]):\n",
    "        intro = \"We will give you examples of English sentences stylized to Japanese syntax that follow or violate the rules of a shared grammar, along with labels 'Yes' or 'No'. You will then generate a label, 'Yes' or 'No', for a new unlabeled sentence that may follow or violate the same grammar rules.\"\n",
    "        # verbs = f\"\"\"The sentences may use verbs ({', '.join(en_verbs)});\"\"\"\n",
    "        # pastTenseVerbs = f\"\"\"or their corresponding past tense forms ({', '.join(en_verbs_past)});\"\"\" \n",
    "        # infinitiveVerbs = f\"\"\"infinitive forms ({', '.join(en_verbs_infinitive)});\"\"\"\n",
    "        # passiveVerbs = f\"\"\"or passive forms ({', '.join(en_verbs_passive)});\"\"\"\n",
    "        # nouns = f\"\"\"The sentences may use nouns ({', '.join(set(en_nouns + en_nouns_plural))}) for the subjects and objects.\"\"\"\n",
    "        # properNouns = f\"\"\"The sentences may use proper nouns ({', '.join(set(proper_nouns))}).\"\"\"\n",
    "        suffixes = f\"\"\"The sentences use Japanese topic markers and suffixes such as wa (commonly used after the subject); o, ni, ga, o-ta (commonly used after the object); reru(used after the verb).\"\"\"\n",
    "        # return f\"\"\"1.{intro}\\n2.{verbs} {pastTenseVerbs} {infinitiveVerbs} {passiveVerbs}\\n3.{nouns}\\n4.{properNouns}\\n5.{suffixes}\"\"\"\n",
    "        return f\"1. {intro}\\n2. {suffixes}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5799da9f-6cd4-4175-82f5-4a7f6679a9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 95687.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if (not (os.path.exists(f\"{PREFIX}/broca/{MODEL_NAME}/experiments/{FINAL_CSV_SUBPATH}/{col}.csv\")) and not (os.path.exists(f\"{PREFIX}/broca/{MODEL_NAME}/experiments/{FINAL_CSV_SUBPATH}/{col}-acc.csv\"))):\n",
    "    master_prompt = get_master_prompt(col)\n",
    "    train_dataset = datasets[col]['train']\n",
    "    test_dataset = datasets[col]['test']\n",
    "    printAnswer = False\n",
    "    f = pd.DataFrame(columns=[\"type\", \"prompt\", \"q\", \"prediction\", \"gold\", \"surprisal\", \"int-grad\"])\n",
    "    for i in tqdm(range(0, len(test_dataset), BATCH_SIZE)):\n",
    "        test_sentences = []\n",
    "        fPrompts = []\n",
    "        fQs = []\n",
    "        fGolds = []\n",
    "        prompts = []\n",
    "        for batch_idx in range(min(BATCH_SIZE, len(test_dataset) - i)):\n",
    "            testBadOrGood = random.choice(['ng-', ''])\n",
    "            test_sentence = test_dataset[i + batch_idx]\n",
    "            prompt = construct_prompt(train_dataset, NUM_DEMONSTRATIONS)\n",
    "            \n",
    "            fPrompt = prompt\n",
    "            \n",
    "            # Append test example\n",
    "            prompt += \"Q: Is this sentence grammatical? Yes or No: \"\n",
    "            prompt += test_sentence[testBadOrGood + col]\n",
    "            prompt += \"\\nA: \"\n",
    "            \n",
    "            fQ = \"Q: Is this sentence grammatical? Yes or No: \" + test_sentence[testBadOrGood + col] + \"\\nA:\"\n",
    "            \n",
    "            if testBadOrGood == 'ng-':\n",
    "                golds.append(\"No\")\n",
    "                fGold = 'No'\n",
    "            else:\n",
    "                golds.append(\"Yes\")\n",
    "                fGold = 'Yes'\n",
    "            fGolds.append(fGold)\n",
    "            prompts.append(f'{master_prompt}\\n\\n{prompt}')\n",
    "            test_sentences.append(test_sentence[testBadOrGood + col])\n",
    "            fPrompts.append(fPrompt)\n",
    "            fQs.append(fQ)\n",
    "        answers = []\n",
    "        if (ABLATION):\n",
    "            for prompt in prompts:\n",
    "                prompt = tokenizer.decode(tokenizer(prompt, padding='max_length', max_length=MAX_LEN)[\"input_ids\"])\n",
    "                with model.trace(prompt, scan=False, validate=False) as tracer:\n",
    "                    for idx, row in mlp_ablate.iterrows():\n",
    "                        model.model.layers[row['layer']].mlp.down_proj.output[0, :len(row['values']), row['neuron']] = torch.tensor(row['values'])\n",
    "                    for idx, row in attn_ablate.iterrows():\n",
    "                        model.model.layers[row['layer']].self_attn.o_proj.output[0, :len(row['values']), row['neuron']] = torch.tensor(row['values'])\n",
    "                    token_ids = model.lm_head.output.argmax(dim=-1).save()\n",
    "                answers.append(model.tokenizer.decode(token_ids[0][-1]))\n",
    "                    \n",
    "            preds = preds + parse_answer(answers)\n",
    "            fPredictions = parse_answer(answers)\n",
    "            for batch_idx in range(len(fPrompts)):\n",
    "                f = pd.concat([f, pd.DataFrame([{'type': col, 'prompt': prompts[batch_idx], 'q' :test_sentences[batch_idx], 'prediction': fPredictions[batch_idx], 'gold': fGolds[batch_idx], 'int-grad': 0}])]).reset_index(drop=True)\n",
    "        else:\n",
    "        # Get answer from model\n",
    "            model_inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True).to('cuda')\n",
    "            answers = model.generate(**model_inputs, pad_token_id=tokenizer.eos_token_id, max_new_tokens=2, top_p=0.9, temperature=0.1, do_sample=True)\n",
    "            answers = tokenizer.batch_decode(answers)[:BATCH_SIZE]\n",
    "            preds = preds + parse_answer(answers)\n",
    "            fPredictions = parse_answer(answers)\n",
    "            fSurprisals = get_aligned_words_measures(test_sentences, parse_answer(answers), \"surp\", model, tokenizer)\n",
    "            for batch_idx in range(len(fPrompts)):\n",
    "                f = pd.concat([f, pd.DataFrame([{'type': col, 'prompt': prompts[batch_idx], 'q' :test_sentences[batch_idx], 'prediction': fPredictions[batch_idx], 'gold': fGolds[batch_idx], 'surprisal': fSurprisals[batch_idx], 'int-grad': 0}])]).reset_index(drop=True)\n",
    "    # Evaluate\n",
    "    accuracy = compute_accuracy(preds, golds)\n",
    "    print(f\"{col} -- Accuracy: {accuracy:.2f}\\n\")\n",
    "    g = pd.concat([g, pd.DataFrame([{ 'trainType' : col, 'testType': col, 'accuracy': f\"{accuracy:.2f}\"}])])\n",
    "    f.to_csv(f\"{PREFIX}/broca/{MODEL_NAME}/experiments/{FINAL_CSV_SUBPATH}/{col}.csv\")\n",
    "    g.to_csv(f'{PREFIX}/broca/{MODEL_NAME}/experiments/{FINAL_CSV_SUBPATH}/{col}-acc.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf213cb5-b01b-40ed-a326-f44fc1338cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will give you examples of English sentences that follow or violate the rules of a shared grammar, along with labels 'Yes' or 'No'. You will then generate a label, 'Yes' or 'No', for a new unlabeled sentence that may follow or violate the same grammar rules.\n",
      "Q: Is this sentence grammatical? Yes or No: the actresses push the mouse\n",
      "A: Yes\n",
      "\n",
      "Q: Is this sentence grammatical? Yes or No: the teacher touches a hat\n",
      "A: Yes\n",
      "\n",
      "Q: Is this sentence grammatical? Yes or No: hits professor the a newspaper\n",
      "A: No\n",
      "\n",
      "Q: Is this sentence grammatical? Yes or No: a reads doctor a chapter\n",
      "A: No\n",
      "\n",
      "Q: Is this sentence grammatical? Yes or No: the actress touches a mouse\n",
      "A: Yes\n",
      "\n",
      "Q: Is this sentence grammatical? Yes or No: the authors read a letter\n",
      "A: Yes\n",
      "\n",
      "Q: Is this sentence grammatical? Yes or No: the professor kicks hat a\n",
      "A: No\n",
      "\n",
      "Q: Is this sentence grammatical? Yes or No: the a eat actresses fish\n",
      "A: No\n",
      "\n",
      "Q: Is this sentence grammatical? Yes or No: the girl espresso a drinks\n",
      "A: No\n",
      "\n",
      "Q: Is this sentence grammatical? Yes or No: the cat pushes a bottle\n",
      "A: Yes\n",
      "\n",
      "Q: Is this sentence grammatical? Yes or No: the doctor drinks the milkshake\n",
      "A: the doctor drinks the milkshake Yes Yes\n"
     ]
    }
   ],
   "source": [
    "print(f['prompt'][0], f['q'][0], f['prediction'][0], f['gold'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67dfb443-7be5-42da-a566-6b9ded111e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>prompt</th>\n",
       "      <th>q</th>\n",
       "      <th>prediction</th>\n",
       "      <th>gold</th>\n",
       "      <th>surprisal</th>\n",
       "      <th>int-grad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>We will give you examples of English sentences...</td>\n",
       "      <td>the doctor drinks the milkshake</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en</td>\n",
       "      <td>We will give you examples of English sentences...</td>\n",
       "      <td>the writers read poem the</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>We will give you examples of English sentences...</td>\n",
       "      <td>the men drink a juice</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en</td>\n",
       "      <td>We will give you examples of English sentences...</td>\n",
       "      <td>the push doctors a fish</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en</td>\n",
       "      <td>We will give you examples of English sentences...</td>\n",
       "      <td>the the push doctors chalk</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>en</td>\n",
       "      <td>We will give you examples of English sentences...</td>\n",
       "      <td>teacher the drinks a tea</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>en</td>\n",
       "      <td>We will give you examples of English sentences...</td>\n",
       "      <td>the a kick girls toy</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>en</td>\n",
       "      <td>We will give you examples of English sentences...</td>\n",
       "      <td>the kick actresses the hat</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>en</td>\n",
       "      <td>We will give you examples of English sentences...</td>\n",
       "      <td>the women kick a newspaper</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>en</td>\n",
       "      <td>We will give you examples of English sentences...</td>\n",
       "      <td>the a touch lawyers hat</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>en</td>\n",
       "      <td>We will give you examples of English sentences...</td>\n",
       "      <td>a pushes writer the toy</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>en</td>\n",
       "      <td>We will give you examples of English sentences...</td>\n",
       "      <td>kick teachers the the newspaper</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>en</td>\n",
       "      <td>We will give you examples of English sentences...</td>\n",
       "      <td>actress a touches the fish</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>en</td>\n",
       "      <td>We will give you examples of English sentences...</td>\n",
       "      <td>the girls kick a mouse</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>en</td>\n",
       "      <td>We will give you examples of English sentences...</td>\n",
       "      <td>the doctors kick a toy</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>en</td>\n",
       "      <td>We will give you examples of English sentences...</td>\n",
       "      <td>the poet reads a poem</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>en</td>\n",
       "      <td>We will give you examples of English sentences...</td>\n",
       "      <td>the dogs the drink water</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>en</td>\n",
       "      <td>We will give you examples of English sentences...</td>\n",
       "      <td>the professor kicks a chalk</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>en</td>\n",
       "      <td>We will give you examples of English sentences...</td>\n",
       "      <td>a cat hits a bottle</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>en</td>\n",
       "      <td>We will give you examples of English sentences...</td>\n",
       "      <td>a boy eats the pear</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>en</td>\n",
       "      <td>We will give you examples of English sentences...</td>\n",
       "      <td>a teacher touches the newspaper</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>en</td>\n",
       "      <td>We will give you examples of English sentences...</td>\n",
       "      <td>the men bottle a push</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>en</td>\n",
       "      <td>We will give you examples of English sentences...</td>\n",
       "      <td>fish actresses touch a the</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>en</td>\n",
       "      <td>We will give you examples of English sentences...</td>\n",
       "      <td>the writer drinks a smoothie</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>en</td>\n",
       "      <td>We will give you examples of English sentences...</td>\n",
       "      <td>the touch cats a newspaper</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>en</td>\n",
       "      <td>We will give you examples of English sentences...</td>\n",
       "      <td>the teachers eat a fish</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>en</td>\n",
       "      <td>We will give you examples of English sentences...</td>\n",
       "      <td>the architects meal a eat</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>en</td>\n",
       "      <td>We will give you examples of English sentences...</td>\n",
       "      <td>the a kicks teacher box</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>en</td>\n",
       "      <td>We will give you examples of English sentences...</td>\n",
       "      <td>the actresses eat a biscuit</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>en</td>\n",
       "      <td>We will give you examples of English sentences...</td>\n",
       "      <td>the cat eats a pear</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>en</td>\n",
       "      <td>We will give you examples of English sentences...</td>\n",
       "      <td>the writers mouse the hit</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>en</td>\n",
       "      <td>We will give you examples of English sentences...</td>\n",
       "      <td>the actresses kick a newspaper</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                             prompt  \\\n",
       "0    en  We will give you examples of English sentences...   \n",
       "1    en  We will give you examples of English sentences...   \n",
       "2    en  We will give you examples of English sentences...   \n",
       "3    en  We will give you examples of English sentences...   \n",
       "4    en  We will give you examples of English sentences...   \n",
       "5    en  We will give you examples of English sentences...   \n",
       "6    en  We will give you examples of English sentences...   \n",
       "7    en  We will give you examples of English sentences...   \n",
       "8    en  We will give you examples of English sentences...   \n",
       "9    en  We will give you examples of English sentences...   \n",
       "10   en  We will give you examples of English sentences...   \n",
       "11   en  We will give you examples of English sentences...   \n",
       "12   en  We will give you examples of English sentences...   \n",
       "13   en  We will give you examples of English sentences...   \n",
       "14   en  We will give you examples of English sentences...   \n",
       "15   en  We will give you examples of English sentences...   \n",
       "16   en  We will give you examples of English sentences...   \n",
       "17   en  We will give you examples of English sentences...   \n",
       "18   en  We will give you examples of English sentences...   \n",
       "19   en  We will give you examples of English sentences...   \n",
       "20   en  We will give you examples of English sentences...   \n",
       "21   en  We will give you examples of English sentences...   \n",
       "22   en  We will give you examples of English sentences...   \n",
       "23   en  We will give you examples of English sentences...   \n",
       "24   en  We will give you examples of English sentences...   \n",
       "25   en  We will give you examples of English sentences...   \n",
       "26   en  We will give you examples of English sentences...   \n",
       "27   en  We will give you examples of English sentences...   \n",
       "28   en  We will give you examples of English sentences...   \n",
       "29   en  We will give you examples of English sentences...   \n",
       "30   en  We will give you examples of English sentences...   \n",
       "31   en  We will give you examples of English sentences...   \n",
       "\n",
       "                                  q prediction gold surprisal int-grad  \n",
       "0   the doctor drinks the milkshake        Yes  Yes       NaN        0  \n",
       "1         the writers read poem the         No   No       NaN        0  \n",
       "2             the men drink a juice        Yes  Yes       NaN        0  \n",
       "3           the push doctors a fish         No   No       NaN        0  \n",
       "4        the the push doctors chalk         No   No       NaN        0  \n",
       "5          teacher the drinks a tea        Yes   No       NaN        0  \n",
       "6              the a kick girls toy         No   No       NaN        0  \n",
       "7        the kick actresses the hat         No   No       NaN        0  \n",
       "8        the women kick a newspaper        Yes  Yes       NaN        0  \n",
       "9           the a touch lawyers hat         No   No       NaN        0  \n",
       "10          a pushes writer the toy         No   No       NaN        0  \n",
       "11  kick teachers the the newspaper         No   No       NaN        0  \n",
       "12       actress a touches the fish         No   No       NaN        0  \n",
       "13           the girls kick a mouse        Yes  Yes       NaN        0  \n",
       "14           the doctors kick a toy         No  Yes       NaN        0  \n",
       "15            the poet reads a poem        Yes  Yes       NaN        0  \n",
       "16         the dogs the drink water         No   No       NaN        0  \n",
       "17      the professor kicks a chalk        Yes  Yes       NaN        0  \n",
       "18              a cat hits a bottle        Yes  Yes       NaN        0  \n",
       "19              a boy eats the pear        Yes  Yes       NaN        0  \n",
       "20  a teacher touches the newspaper        Yes  Yes       NaN        0  \n",
       "21            the men bottle a push         No   No       NaN        0  \n",
       "22       fish actresses touch a the         No   No       NaN        0  \n",
       "23     the writer drinks a smoothie        Yes  Yes       NaN        0  \n",
       "24       the touch cats a newspaper         No   No       NaN        0  \n",
       "25          the teachers eat a fish        Yes  Yes       NaN        0  \n",
       "26        the architects meal a eat         No   No       NaN        0  \n",
       "27          the a kicks teacher box         No   No       NaN        0  \n",
       "28      the actresses eat a biscuit        Yes  Yes       NaN        0  \n",
       "29              the cat eats a pear        Yes  Yes       NaN        0  \n",
       "30        the writers mouse the hit         No   No       NaN        0  \n",
       "31   the actresses kick a newspaper         No  Yes       NaN        0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838b3990-4171-4bc9-86c0-222f561157dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
