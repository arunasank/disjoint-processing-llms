1
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:26<02:10, 26.06s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:56<01:54, 28.69s/it]Loading checkpoint shards:  50%|█████     | 3/6 [01:39<01:45, 35.30s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [02:18<01:13, 36.55s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [02:57<00:37, 37.38s/it]Loading checkpoint shards: 100%|██████████| 6/6 [03:26<00:00, 34.63s/it]Loading checkpoint shards: 100%|██████████| 6/6 [03:26<00:00, 34.39s/it]
Layer 0
/home/gridsan/arunas/.local/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:226: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.
  warnings.warn(f'Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.')
Layer 1
Layer 2
Layer 3
Layer 4
Layer 5
Layer 6
Layer 7
Layer 8
Layer 9
Layer 10
Layer 11
Layer 12
Layer 13
Layer 14
Layer 15
Layer 16
Layer 17
Layer 18
Layer 19
Layer 20
Layer 21
Layer 22
Layer 23
Layer 24
Layer 25
Layer 26
Layer 27
Layer 28
Layer 29
Layer 30
Layer 31
Layer 32
subordinate-sentence {0: {0: -0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: -0.0, 7: -0.0}, 1: {0: -0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: -0.0, 5: 0.0, 6: -0.0, 7: 0.0}, 2: {0: -0.07, 1: -0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0}, 3: {0: -0.07, 1: -0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0}, 4: {0: -0.07, 1: -0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0}, 5: {0: -0.07, 1: -0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0}, 6: {0: -0.07, 1: -0.0, 2: -0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0}, 7: {0: -0.07, 1: -0.0, 2: -0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0}, 8: {0: -0.07, 1: -0.0, 2: -0.0, 3: -0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0}, 9: {0: -0.07, 1: -0.0, 2: -0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0}, 10: {0: -0.07, 1: -0.0, 2: -0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0}, 11: {0: -0.07, 1: -0.0, 2: -0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0}, 12: {0: -0.07, 1: -0.0, 2: -0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0}, 13: {0: -0.07, 1: -0.0, 2: -0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0}, 14: {0: -0.07, 1: 0.0, 2: -0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0}, 15: {0: -0.07, 1: 0.0, 2: -0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0}, 16: {0: -0.07, 1: 0.0, 2: -0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0}, 17: {0: -0.07, 1: 0.0, 2: -0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0}, 18: {0: -0.07, 1: 0.0, 2: -0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0}, 19: {0: -0.07, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0}, 20: {0: -0.07, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0}, 21: {0: -0.07, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0}, 22: {0: -0.07, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0}, 23: {0: -0.07, 1: 0.0, 2: 0.0, 3: -0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0}, 24: {0: -0.07, 1: 0.0, 2: 0.0, 3: -0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0}, 25: {0: -0.07, 1: -0.0, 2: -0.0, 3: -0.0, 4: -0.0, 5: 0.0, 6: 0.0, 7: 0.0}, 26: {0: -0.07, 1: 0.0, 2: 0.0, 3: -0.0, 4: -0.0, 5: -0.0, 6: 0.0, 7: 0.0}, 27: {0: -0.07, 1: 0.0, 2: 0.0, 3: -0.0, 4: -0.0, 5: 0.0, 6: 0.0, 7: 0.0}, 28: {0: -0.07, 1: 0.0, 2: 0.0, 3: -0.0, 4: -0.0, 5: 0.0, 6: 0.0, 7: 0.0}, 29: {0: -0.07, 1: 0.0, 2: 0.0, 3: -0.0, 4: -0.0, 5: 0.0, 6: 0.0, 7: 0.0}, 30: {0: -0.08, 1: 0.0, 2: -0.0, 3: -0.0, 4: -0.0, 5: 0.0, 6: 0.0, 7: 0.0}, 31: {0: -0.08, 1: 0.0, 2: 0.0, 3: -0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0}, 32: {0: 0.01, 1: 0.03, 2: -0.03, 3: -0.06, 4: -0.06, 5: -0.05, 6: -0.04, 7: -0.04}}
